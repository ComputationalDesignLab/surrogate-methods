

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Uncertainty Analysis &#8212; AAE 590 Surrogate Methods</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'uncertainty_analysis';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Multiobjective optimization using Kriging models" href="multi_objective/krg_multi_objective.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="index.html">
  
  
  
  
  
  
    <p class="title logo__title">AAE 590 Surrogate Methods</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="index.html">
                    Introduction
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="setup.html">Computing environment setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="resources.html">Python and Jupyter notebook resources</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="review_nm/intro.html">Review of Numerical Methods and Probability</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="review_nm/error.html">Error estimation for iterative method</a></li>
<li class="toctree-l2"><a class="reference internal" href="review_nm/num_diff.html">Numerical Differentiation</a></li>
<li class="toctree-l2"><a class="reference internal" href="review_nm/uniform.html">Uniform Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="review_nm/norm.html">Normal Distribution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="prob_form.html">Problem Formulation</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="local_opt/intro.html">Local Optimization</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="local_opt/unconst.html">Unconstrained Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="local_opt/const.html">Constrained Optimization</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="global_opt/intro.html">Global Optimization</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="global_opt/multi.html">Multistart Gradient-based Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="global_opt/pso.html">Particle Swarm Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="global_opt/de.html">Differential Evolution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="doe.html">Sampling Plans</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="basic_sm/intro.html">Basic Surrogate Models</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="basic_sm/ls_regression.html">Linear Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="basic_sm/poly.html">Polynomial Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="basic_sm/rbf.html">Radial Basis Function Model</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="krg.html">Gaussian Process based Models</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="seq_sampling/intro.html">Sequential Sampling</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="seq_sampling/exploitation.html">Exploitation</a></li>
<li class="toctree-l2"><a class="reference internal" href="seq_sampling/exploration.html">Exploration</a></li>
<li class="toctree-l2"><a class="reference internal" href="seq_sampling/lcb.html">Lower Confidence Bound</a></li>
<li class="toctree-l2"><a class="reference internal" href="seq_sampling/pi.html">Probability of Improvement</a></li>
<li class="toctree-l2"><a class="reference internal" href="seq_sampling/ei.html">Expected Improvement</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="const_seq_sampling/intro.html">Constrained Sequential Sampling</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="const_seq_sampling/const_exploit.html">Constrained Exploitation</a></li>
<li class="toctree-l2"><a class="reference internal" href="const_seq_sampling/const_explor.html">Constrained Exploration</a></li>
<li class="toctree-l2"><a class="reference internal" href="const_seq_sampling/const_ei.html">Constrained Expected Improvement</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="sens_analysis/intro.html">Sensitivity Analysis</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="sens_analysis/local.html">Local Sensitivity Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="sens_analysis/global.html">Global Sensitivity Analysis</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="dim_reduction/intro.html">Dimensionality Reduction</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="dim_reduction/dim_red_methods.html">Dimensionality Reduction Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="dim_reduction/seq_sampling.html">Sequential Sampling using Dimensionality Reduction</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="engineering_design.html">Engineering Modeling and Design Optimization</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="multi_objective/intro_moo.html">Multiobjective Optimization</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="multi_objective/multi_objective_optimization.html">Multiobjective optimization using differential evolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="multi_objective/krg_multi_objective.html">Multiobjective optimization using Kriging models</a></li>
</ul>
</li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Uncertainty Analysis</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/uncertainty_analysis.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Uncertainty Analysis</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#calculation-of-statistics-mean-and-standard-deviation-of-objective-function">Calculation of statistics (mean and standard deviation) of objective function</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mcs-method-for-a-large-number-of-samples">MCS method for a large number of samples</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#convergence-of-the-mcs-method">Convergence of the MCS method</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#probability-of-feasibility-of-a-constraint">Probability of feasibility of a constraint</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="uncertainty-analysis">
<h1>Uncertainty Analysis<a class="headerlink" href="#uncertainty-analysis" title="Permalink to this heading">#</a></h1>
<p>This section demonstrates the use of the Monte Carlo sampling (MCS) method for forward propagation of uncertainty. In uncertainty analysis, it is of interest to quantify how uncertain design variables or parameters of a problem affect the quantity of interest (QoI) for a given system. This is done by sampling the distribution of the uncertain variables or parameters using a sampling method and calculating the QoI for a large number of samples. The required statistics (mean, standard deviation, reliability) can then be calculated from the QoI values that are generated using MCS. In the context of optimization, the statistics of interest are typically the mean and standard deviation of the objective function and the reliability of the constraint.</p>
<p>To illustrate the ideas of uncertainty analysis, consider a problem with the following objective and constraint</p>
<div class="math notranslate nohighlight">
\[Y = f(\textbf{x}) = x_1^2 + 2x_2^2 + 3x_3^2\]</div>
<div class="math notranslate nohighlight">
\[g(\textbf{x}) = x_1 + x_2 + x_3 - 3.5 \leq 0\]</div>
<p>In this problem, <span class="math notranslate nohighlight">\(x_1\)</span> is deterministic and other two variables are normally distributed with standard deviations: <span class="math notranslate nohighlight">\(\sigma_2 = 0.06\)</span> and <span class="math notranslate nohighlight">\(\sigma_3 = 0.2\)</span>. For the following analysis, the design variable values used are <span class="math notranslate nohighlight">\(x = [1,1,1]^T\)</span>. This means that <span class="math notranslate nohighlight">\(x_1 = 1\)</span>, <span class="math notranslate nohighlight">\(x_2 \sim \mathcal{N}(1,0.06)\)</span>, and <span class="math notranslate nohighlight">\(x_3 \sim \mathcal{N}(1, 0.2)\)</span>.</p>
<p>The first block of code below imports the required packages to perform the uncertainty analysis.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">uniform</span><span class="p">,</span> <span class="n">norm</span>
<span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">time</span>
<span class="kn">from</span> <span class="nn">smt.sampling_methods</span> <span class="kn">import</span> <span class="n">LHS</span>
<span class="kn">from</span> <span class="nn">scipy.stats.qmc</span> <span class="kn">import</span> <span class="n">Halton</span><span class="p">,</span> <span class="n">scale</span>
</pre></div>
</div>
</div>
</div>
<section id="calculation-of-statistics-mean-and-standard-deviation-of-objective-function">
<h2>Calculation of statistics (mean and standard deviation) of objective function<a class="headerlink" href="#calculation-of-statistics-mean-and-standard-deviation-of-objective-function" title="Permalink to this heading">#</a></h2>
<p>This subsection will discuss the calculation of the statistics of the objective function based on the uncertain design variables. At the start, the general idea of the MCS method will be demonstrated where a large number of samples will be drawn from the distributions of the random variables using random sampling and Halton sequences. The objective function statistics and distribution will be calculated based on the samples that are generated the value of the objective function for those samples. However, when using the MCS method it is also important to determine the minimum number of samples that can accurately obtain the statistics of a model to reduce computational cost. This is done by varying the number of samples from small to large values and observing the change in the mean and standard deviation. The minimum number of samples for which there is no significant change in the estimated mean and standard deviation from the previous number of samples used can be used to obtain the statistics of the objective function. Typically, one would start the analysis by performing the convergence of the MCS method to find the minimum number of samples.</p>
<p>The next block of code defines the objective function and constraint of the problem.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">function</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">x3</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function for computing objective values</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="n">value</span> <span class="o">=</span> <span class="n">x1</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="n">x2</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">3</span><span class="o">*</span><span class="n">x3</span><span class="o">**</span><span class="mi">2</span>
    
    <span class="k">return</span> <span class="n">value</span>

<span class="k">def</span> <span class="nf">constraint</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">x3</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function for computing constraint values</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">value</span> <span class="o">=</span> <span class="n">x1</span> <span class="o">+</span> <span class="n">x2</span> <span class="o">+</span> <span class="n">x3</span> <span class="o">-</span> <span class="mf">3.5</span>

    <span class="k">return</span> <span class="n">value</span>
</pre></div>
</div>
</div>
</div>
<section id="mcs-method-for-a-large-number-of-samples">
<h3>MCS method for a large number of samples<a class="headerlink" href="#mcs-method-for-a-large-number-of-samples" title="Permalink to this heading">#</a></h3>
<p>The first demonstration of MCS is with <strong>random sampling</strong>. The block of code below defines random variables for <span class="math notranslate nohighlight">\(x_2\)</span> and <span class="math notranslate nohighlight">\(x_3\)</span>, and performs MCS with 1,000,000 random samples for computing mean, standard deviation, and the output distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Defining random variables</span>
<span class="n">rv_x2</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">0.06</span><span class="p">)</span>
<span class="n">rv_x3</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">num_samples</span> <span class="o">=</span> <span class="mi">1000000</span>

<span class="n">x1</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">rv_x2</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">num_samples</span><span class="p">)</span>
<span class="n">x3</span> <span class="o">=</span> <span class="n">rv_x3</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">num_samples</span><span class="p">)</span>

<span class="n">f_random_</span> <span class="o">=</span> <span class="n">function</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">x3</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">f_random_</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Probability density&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;$Y$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Number of samples: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">num_samples</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Estimated mean (true): </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">f_random_</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Estimated standard deviation (true): </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">f_random_</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Estimated mean (true): 6.126466640290937
Estimated standard deviation (true): 1.2359362998688583
</pre></div>
</div>
<img alt="_images/c198b3aac069727ee05a24422f961f6b924fb0770589d9850fe02e32577559b2.png" src="_images/c198b3aac069727ee05a24422f961f6b924fb0770589d9850fe02e32577559b2.png" />
</div>
</div>
<p>From the above MCS with random sampling, the <span class="math notranslate nohighlight">\(\mu\)</span> is 6.13 and <span class="math notranslate nohighlight">\(\sigma\)</span> is 1.23. This distribution is slightly asymmetric and has a longer right tail.</p>
<p>In the second demonstration of MCS, the samples from the distribution will be drawn according to <strong>Halton sequences</strong>. In the context of sampling distributions, Halton sequences generated on a unit hypercube (values are generated between the bounds of 0 and 1) represent probabilities of the occurrence of a realization of a random design variable or parameter. These probabilities can then be transformed into the realizations of the random design variable or parameter using the inverse CDF function of the distribution of the random design variable or parameter. In this way, samples can be drawn from the distributions of the uncertain variables and parameters and MCS can be performed.</p>
<p>The block of code below demonstrates this approach of using Halton sequences to perform MCS. Like the previous example of random sampling, the mean, standard deviation and output distribution are computed using 1,000,000 samples.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Defining the Halton sampler</span>
<span class="n">halton_sampler</span> <span class="o">=</span> <span class="n">Halton</span><span class="p">(</span><span class="n">d</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">scramble</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> 
<span class="c1"># scramble is set to false to avoid Owen scrambling which is used to create non-deterministic Halton sequences</span>

<span class="n">num_samples</span> <span class="o">=</span> <span class="mi">1000000</span>

<span class="c1"># Generating halton sequence samples and transforming them according to the distributions of the random variables</span>
<span class="n">x1</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">x_halton</span> <span class="o">=</span> <span class="n">halton_sampler</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">n</span> <span class="o">=</span> <span class="n">num_samples</span><span class="p">)</span>
<span class="n">x_halton</span> <span class="o">=</span> <span class="n">x_halton</span><span class="p">[</span><span class="mi">1</span><span class="p">:,:]</span> <span class="c1"># Dropping the first element [0,0] of the Halton sequence since inverse CDF of 0 will be inf</span>
<span class="n">x2_halton</span> <span class="o">=</span> <span class="n">rv_x2</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">x_halton</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span>
<span class="n">x3_halton</span> <span class="o">=</span> <span class="n">rv_x3</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">x_halton</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span>

<span class="n">f_halton</span> <span class="o">=</span> <span class="n">function</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2_halton</span><span class="p">,</span> <span class="n">x3_halton</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">f_halton</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Probability density&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;$Y$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Number of samples: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">num_samples</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Estimated mean (Halton): </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">f_halton</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Estimated standard deviation (Halton): </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">f_halton</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Estimated mean (Halton): 6.12716999446928
Estimated standard deviation (Halton): 1.235459444685999
</pre></div>
</div>
<img alt="_images/2b636e12bae47efaaa7393a303fe41829e4897a5255773097d324865fc5c72ac.png" src="_images/2b636e12bae47efaaa7393a303fe41829e4897a5255773097d324865fc5c72ac.png" />
</div>
</div>
<p>The <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span> obtained using Halton sequences closely matches the values obtained using random sampling. The output distribution is also a good match for the one obtained using random sampling.</p>
</section>
<section id="convergence-of-the-mcs-method">
<h3>Convergence of the MCS method<a class="headerlink" href="#convergence-of-the-mcs-method" title="Permalink to this heading">#</a></h3>
<p>Now, MCS will be performed using <strong>random sampling</strong>, <strong>Latin Hypercube sampling (LHS)</strong> and <strong>Halton sequences</strong> using a varied number of samples drawn from the distribution. The previous analysis used a fixed number of samples to perform the MCS but in the following analysis, the number of samples used for the MCS will be varied and the statistics will be calculated at every number of samples. In this case, LHS and Halton sequences are used to generate samples between the bounds of 0 and 1. As mentioned previously, these values are treated as probabilities and the inverse CDF of the random variables is used to draw samples from the distribution based on the values of these probabilities.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Defining different samples sizes for MCS</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>

<span class="c1"># Defining the LHS sampler</span>
<span class="n">lhs_sampler</span> <span class="o">=</span> <span class="n">LHS</span><span class="p">(</span><span class="n">xlimits</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">]]),</span> <span class="n">criterion</span><span class="o">=</span><span class="s2">&quot;ese&quot;</span><span class="p">)</span>

<span class="c1"># Storing statistics</span>
<span class="n">mean_lhs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">sigma_lhs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">mean_halton</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">sigma_halton</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">mean_random</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">sigma_random</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Storing the function values</span>
<span class="n">F_lhs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">F_random</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">F_halton</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">:</span>
    
    <span class="c1"># LHS sampling</span>
    <span class="n">x_lhs</span> <span class="o">=</span> <span class="n">lhs_sampler</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
    <span class="n">x2_lhs</span> <span class="o">=</span> <span class="n">rv_x2</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">x_lhs</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">x3_lhs</span> <span class="o">=</span> <span class="n">rv_x3</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">x_lhs</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">x1</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">f_lhs</span> <span class="o">=</span> <span class="n">function</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2_lhs</span><span class="p">,</span> <span class="n">x3_lhs</span><span class="p">)</span>
    <span class="n">mean_lhs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">f_lhs</span><span class="p">))</span>
    <span class="n">sigma_lhs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">f_lhs</span><span class="p">))</span>
    <span class="n">F_lhs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f_lhs</span><span class="p">)</span>

    <span class="c1"># Halton sampling</span>
    <span class="n">x_halton</span> <span class="o">=</span> <span class="n">halton_sampler</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">n</span> <span class="o">=</span> <span class="n">sample</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">sample</span> <span class="o">==</span> <span class="n">samples</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
        <span class="n">x_halton</span> <span class="o">=</span> <span class="n">x_halton</span><span class="p">[</span><span class="mi">1</span><span class="p">:,:]</span> <span class="c1"># Dropping the first element [0,0] of the Halton sequence since inverse CDF of 0 will be inf</span>
    <span class="n">x2_halton</span> <span class="o">=</span> <span class="n">rv_x2</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">x_halton</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">x3_halton</span> <span class="o">=</span> <span class="n">rv_x3</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">x_halton</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">f_halton</span> <span class="o">=</span> <span class="n">function</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2_halton</span><span class="p">,</span> <span class="n">x3_halton</span><span class="p">)</span>
    <span class="n">mean_halton</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">f_halton</span><span class="p">))</span>
    <span class="n">sigma_halton</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">f_halton</span><span class="p">))</span>
    <span class="n">F_halton</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f_halton</span><span class="p">)</span>
    
    <span class="c1"># Random sampling</span>
    <span class="n">x2</span> <span class="o">=</span> <span class="n">rv_x2</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">sample</span><span class="p">)</span>
    <span class="n">x3</span> <span class="o">=</span> <span class="n">rv_x3</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">sample</span><span class="p">)</span>
    <span class="n">f_random</span> <span class="o">=</span> <span class="n">function</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">x3</span><span class="p">)</span>
    <span class="n">mean_random</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">f_random</span><span class="p">))</span>
    <span class="n">sigma_random</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">f_random</span><span class="p">))</span>
    <span class="n">F_random</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f_random</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The next block of code plots the convergence history of the MCS with different number of samples. The convergence history plots the convergence of the mean and standard deviation versus the number of samples used in the MCS. The relative change in the mean and standard deviation versus the number of samples is also plotted. A tolerance for the relative change in the statistics can be used to determine when the MCS has converged. This can be used to determine the number of MCS samples required to accurately determine the statistics of the objective function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">mean_lhs</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;LHS&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">mean_random</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Random&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">mean_halton</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Halton&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;$\mu$&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Number of samples&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">sigma_lhs</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;LHS&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">sigma_random</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Random&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">sigma_halton</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Halton&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;$\sigma$&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Number of samples&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>

<span class="n">conv_mean_lhs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">conv_mean_random</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">conv_mean_halton</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">conv_sigma_lhs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">conv_sigma_random</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">conv_sigma_halton</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">conv_mean_lhs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">mean_lhs</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">mean_lhs</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">mean_lhs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">conv_mean_random</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">mean_random</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">mean_random</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">mean_random</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">conv_mean_halton</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">mean_halton</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">mean_halton</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">mean_halton</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">conv_sigma_lhs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">sigma_lhs</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">sigma_lhs</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">sigma_lhs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">conv_sigma_random</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">sigma_random</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">sigma_random</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">sigma_random</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">conv_sigma_halton</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">sigma_halton</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">sigma_halton</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">sigma_halton</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">conv_mean_lhs</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;LHS&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">conv_mean_random</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Random&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">conv_mean_halton</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Halton&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;$ |\mu^{(i)} - \mu^{(i-1)}| / |\mu^{(0)}|$&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Number of samples&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_yscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">conv_sigma_lhs</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;LHS&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">conv_sigma_random</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Random&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">conv_sigma_halton</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Halton&quot;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;$ |\sigma^{(i)} - \sigma^{(i-1)}| / |\sigma^{(0)}|$&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Number of samples&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_yscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/e016715458dd79b49fa80ef06b063d5c307499cfeeaf57d30c38a851b6406866.png" src="_images/e016715458dd79b49fa80ef06b063d5c307499cfeeaf57d30c38a851b6406866.png" />
<img alt="_images/06dde0e6f567ce5c22046b67e75944c214d87cc3adf39c76825816cb44dd565f.png" src="_images/06dde0e6f567ce5c22046b67e75944c214d87cc3adf39c76825816cb44dd565f.png" />
<img alt="_images/c5fddb175d319c48b7b4707d6fe4d4940ed213cc959ff91aaf39cc9e2ace5341.png" src="_images/c5fddb175d319c48b7b4707d6fe4d4940ed213cc959ff91aaf39cc9e2ace5341.png" />
<img alt="_images/b9638a2ec526c94b8b2aecfa43c7df47c6390ff7a8658846dcd2ed8584ccfdd2.png" src="_images/b9638a2ec526c94b8b2aecfa43c7df47c6390ff7a8658846dcd2ed8584ccfdd2.png" />
</div>
</div>
<p>Notice that as the number of samples increase, the <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span> also converge to the value obtained from MCS in the previous block of code. The above convergence plots show the benefit of using LHS and Halton sequences to sample the distribution as compared to using random sampling. MCS performed using LHS and Halton sequences tends to converge faster to the known values of <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span>. This can be deduced from the quick reduction in the relative change of the mean and standard deviation that is brought by using the LHS and Halton sequence sampling method. It is also deduced from the variation of mean and standard deviation with the number of samples as the values converge to those obtained from performing MCS using a large number of samples. This means a lower number of samples must be drawn from the distribution and evaluated to calculate the statistics. This reduces the computational cost of performing the uncertainty analysis.</p>
<p>A similar convergence history can also be plotted for the output distribution of the objective function. This is done in the next code block. This convergence history shows that the output distribution closely matches the true distribution as the number of samples increases. Here, the distribution obtained using random sampling and <span class="math notranslate nohighlight">\(10^6\)</span> MCS samples in an earlier code block is treated as the true distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">),</span> <span class="mi">2</span><span class="p">):</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">f_random_</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s2">&quot;red&quot;</span><span class="p">,</span><span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;True&#39;</span><span class="p">)</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">F_lhs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;LHS&#39;</span><span class="p">)</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">F_random</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Random&#39;</span><span class="p">)</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">F_halton</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;Halton&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Probability density&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;$Y$&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Number of samples: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/fd602ff8b9bee36e533a3126b238dd49e41eeb39b148d4c59b8d34e933beb304.png" src="_images/fd602ff8b9bee36e533a3126b238dd49e41eeb39b148d4c59b8d34e933beb304.png" />
<img alt="_images/9b0547adc0f60eb3146fbe50ae26d1b6f24b18504f835722034b49ce75b0b9c8.png" src="_images/9b0547adc0f60eb3146fbe50ae26d1b6f24b18504f835722034b49ce75b0b9c8.png" />
<img alt="_images/0bdc791ef170f4ee102f1c55ea73a73b2e9f33eb895c078de25169c546642b9f.png" src="_images/0bdc791ef170f4ee102f1c55ea73a73b2e9f33eb895c078de25169c546642b9f.png" />
<img alt="_images/e214606db06b2488d95f757c90b87592ccfbbac5be9b450e22c6e112c4cc5fef.png" src="_images/e214606db06b2488d95f757c90b87592ccfbbac5be9b450e22c6e112c4cc5fef.png" />
<img alt="_images/fda3d940d7d53f6f4b053cba121602cb626dcc14bf53f04ae5d6412c99101cdb.png" src="_images/fda3d940d7d53f6f4b053cba121602cb626dcc14bf53f04ae5d6412c99101cdb.png" />
<img alt="_images/379ad93f15ba847d7c7ed9b6cf5679f2dab9008bcc7af57064523a9cd5daadfb.png" src="_images/379ad93f15ba847d7c7ed9b6cf5679f2dab9008bcc7af57064523a9cd5daadfb.png" />
<img alt="_images/912b7331d45e2c5a0f169e478e69ee5abba880c722d5e8c167a57d6578ed287f.png" src="_images/912b7331d45e2c5a0f169e478e69ee5abba880c722d5e8c167a57d6578ed287f.png" />
<img alt="_images/8f80954c562072a27fceddac1e1ea55b77c2909aae3943eacf0150f3ab678384.png" src="_images/8f80954c562072a27fceddac1e1ea55b77c2909aae3943eacf0150f3ab678384.png" />
<img alt="_images/09e568c6d3f33196008e18cfcd8733d07ce67bd4ad8393d917cfb70dcdd93e71.png" src="_images/09e568c6d3f33196008e18cfcd8733d07ce67bd4ad8393d917cfb70dcdd93e71.png" />
<img alt="_images/adabf00596d2451543581496fc69d5e215d1b5d087c68e53d2ede12b1673fd5b.png" src="_images/adabf00596d2451543581496fc69d5e215d1b5d087c68e53d2ede12b1673fd5b.png" />
</div>
</div>
</section>
</section>
<section id="probability-of-feasibility-of-a-constraint">
<h2>Probability of feasibility of a constraint<a class="headerlink" href="#probability-of-feasibility-of-a-constraint" title="Permalink to this heading">#</a></h2>
<p>When working with uncertainty in design variables or parameters for an optimization problem, the probability of feasibility of a constraint
is of interest to a designer. The probability of feasibility of the constraint used as an example in this section can be calculated using MCS. The distributions of the uncertain variables can be sampled using the methods shown previously and for each sample, the value of the constraint can be calculated. Once all the samples are evaluated, the required probability can be calculated by simply dividing the number of samples that satisfy the constraint by the total number of samples.</p>
<div class="math notranslate nohighlight">
\[\text{Pr}(g(\textbf{x}) \leq 0) \approx \frac{\text{number of feasible samples}}{\text{total number of samples}}\]</div>
<p>Similar to the previous section, the next block of code uses random sampling and a large number of MCS samples to calculate the true probability of feasibility of the constraint.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_samples</span> <span class="o">=</span> <span class="mi">1000000</span>

<span class="n">x1</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">rv_x2</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">num_samples</span><span class="p">)</span>
<span class="n">x3</span> <span class="o">=</span> <span class="n">rv_x3</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">num_samples</span><span class="p">)</span>

<span class="n">g_random_</span> <span class="o">=</span> <span class="n">constraint</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">x3</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Estimated probability of feasibility (true): </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">g_random_</span><span class="p">[</span><span class="n">g_random_</span><span class="o">&lt;=</span><span class="mi">0</span><span class="p">])</span><span class="o">/</span><span class="n">num_samples</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Estimated probability of feasibility (true): 0.991489
</pre></div>
</div>
</div>
</div>
<p>The next block of code uses the LHS and Halton sequence sampling methods along with random sampling to calculate the reliability of the constraint. The number of samples used for MCS is varied and the variation of the reliability with number of samples is plotted to visualize the convergence.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Defining different samples sizes for MCS</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>

<span class="c1"># Storing reliabilities</span>
<span class="n">p_lhs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">p_halton</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">p_random</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">:</span>

    <span class="c1"># LHS sampling</span>
    <span class="n">x_lhs</span> <span class="o">=</span> <span class="n">lhs_sampler</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
    <span class="n">x2_lhs</span> <span class="o">=</span> <span class="n">rv_x2</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">x_lhs</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">x3_lhs</span> <span class="o">=</span> <span class="n">rv_x3</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">x_lhs</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">x1</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">g_lhs</span> <span class="o">=</span> <span class="n">constraint</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2_lhs</span><span class="p">,</span> <span class="n">x3_lhs</span><span class="p">)</span>
    <span class="n">p_lhs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">g_lhs</span><span class="p">[</span><span class="n">g_lhs</span><span class="o">&lt;=</span><span class="mi">0</span><span class="p">])</span><span class="o">/</span><span class="n">sample</span><span class="p">)</span>

    <span class="c1"># Halton sampling</span>
    <span class="n">x_halton</span> <span class="o">=</span> <span class="n">halton_sampler</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">n</span> <span class="o">=</span> <span class="n">sample</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">sample</span> <span class="o">==</span> <span class="n">samples</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
        <span class="n">x_halton</span> <span class="o">=</span> <span class="n">x_halton</span><span class="p">[</span><span class="mi">1</span><span class="p">:,:]</span> <span class="c1"># Dropping the first element [0,0] of the Halton sequence since inverse CDF of 0 will be inf</span>
    <span class="n">x2_halton</span> <span class="o">=</span> <span class="n">rv_x2</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">x_halton</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">x3_halton</span> <span class="o">=</span> <span class="n">rv_x3</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">x_halton</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">g_halton</span> <span class="o">=</span> <span class="n">constraint</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2_halton</span><span class="p">,</span> <span class="n">x3_halton</span><span class="p">)</span>
    <span class="n">p_halton</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">g_halton</span><span class="p">[</span><span class="n">g_halton</span><span class="o">&lt;=</span><span class="mi">0</span><span class="p">])</span><span class="o">/</span><span class="n">sample</span><span class="p">)</span>
    
    <span class="c1"># Random sampling</span>
    <span class="n">x2</span> <span class="o">=</span> <span class="n">rv_x2</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">sample</span><span class="p">)</span>
    <span class="n">x3</span> <span class="o">=</span> <span class="n">rv_x3</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">sample</span><span class="p">)</span>
    <span class="n">g_random</span> <span class="o">=</span> <span class="n">constraint</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">x3</span><span class="p">)</span>
    <span class="n">p_random</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">g_random</span><span class="p">[</span><span class="n">g_random</span><span class="o">&lt;=</span><span class="mi">0</span><span class="p">])</span><span class="o">/</span><span class="n">sample</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">r_lhs</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;LHS&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">r_random</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Random&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">r_halton</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Halton&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Probability of Feasibility&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Number of samples&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/47b48f17a317fd0a1f2451abdf6df31ff382cc762bd90efd1a3f75892a3e5d6a.png" src="_images/47b48f17a317fd0a1f2451abdf6df31ff382cc762bd90efd1a3f75892a3e5d6a.png" />
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="multi_objective/krg_multi_objective.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Multiobjective optimization using Kriging models</p>
      </div>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#calculation-of-statistics-mean-and-standard-deviation-of-objective-function">Calculation of statistics (mean and standard deviation) of objective function</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mcs-method-for-a-large-number-of-samples">MCS method for a large number of samples</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#convergence-of-the-mcs-method">Convergence of the MCS method</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#probability-of-feasibility-of-a-constraint">Probability of feasibility of a constraint</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Leifur Leifsson (leifur[at]purdue.edu)
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>