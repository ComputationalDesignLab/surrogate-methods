{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7c8ee5b",
   "metadata": {},
   "source": [
    "Review of Numerical Methods\n",
    "=========\n",
    "\n",
    "This workbook supports the material taught in the class for review of numerical methods. It contains following topics:\n",
    "\n",
    "1. [Error estimation for iterative method](#Error-estimation-for-iterative-method)    \n",
    "2. [Numerical Differentiation](#Numerical-Differentiation)      \n",
    "3. [Least Squares Regresion](#Least-Squares-Regresion)\n",
    "\n",
    "Please go through this notebook entirely and reach out to teaching team if you have any doubts. \n",
    "\n",
    "**Please run the below block of code before you run any other block** - it imports all the packages needed for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f11156b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9707d55d",
   "metadata": {},
   "source": [
    "Error estimation for iterative method\n",
    "-----------\n",
    "\n",
    "Determine the number of terms necessary to approximate $cos(x)$ to 8 significant figures at $x = 0.3\\pi$ using the following Maclaurin series approximation.\n",
    "\n",
    "$$\n",
    "    cos(x) = 1 - \\frac{x^2}{2!} + \\frac{x^4}{4!} - \\frac{x^6}{6!} + \\frac{x^8}{8!} - ...\n",
    "$$\n",
    "\n",
    "Assume that you don't know the true value.\n",
    "\n",
    "**Solution**:\n",
    "\n",
    "To find whether an approximation is accurate upto $n$ significant figures, following formula can be used:\n",
    "\n",
    "$$\n",
    "    \\epsilon_s = (0.5 \\times 10^{2-n})\\%\n",
    "$$\n",
    "\n",
    "Note the percantage sign in the formula. To get 8 significant figures, error should be less than $\\epsilon_s = (5e-7)\\% \\text{ or } 5e-9$. We can compute the approximate error ($\\epsilon _a$) while we do the iterations and use $\\epsilon_s$ as a stopping criteria. The code in the next block implements this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df8e9c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maclaurin_cos(x, num):\n",
    "    \"\"\"\n",
    "        Function for computing maclaurin series approximation for cosine.\n",
    "        Input:\n",
    "        x - value at which cosine approximation is needed.\n",
    "        num - number of terms in the series (includes the leading 1).\n",
    "    \"\"\"\n",
    "    value = 0\n",
    "    \n",
    "    for i in range(num):\n",
    "        power = 2*i\n",
    "        value = value + (-1)**i * x**power / math.factorial(power)\n",
    "\n",
    "    return value\n",
    "\n",
    "def find_req_num_terms(func, x, num):\n",
    "    \"\"\"\n",
    "        Function to find number of terms needed to achieve \n",
    "        accuracy upto certain significant numbers.\n",
    "        \n",
    "        Input:\n",
    "        func - python function which computes a series\n",
    "        x - value of x at which approximation is required\n",
    "        num - number of significant figures required\n",
    "    \"\"\"\n",
    "    \n",
    "    # Tolerance for required significant figures\n",
    "    tolerance = 0.5*10**(2-num)\n",
    "    \n",
    "    # Performing 1st iteration\n",
    "    terms = 1\n",
    "    approx_value = maclaurin_cos(x, terms)\n",
    "    \n",
    "    # Initial value of error for starting the iteration\n",
    "    print(\"Number of terms: 1\")\n",
    "    print(\"Approx value: {}\".format(approx_value))\n",
    "    print(\"Approx errror: -\\n\")\n",
    "    approx_error = 1\n",
    "    \n",
    "    # Performing iterations\n",
    "    while abs(approx_error) >= tolerance:\n",
    "        # Increment the number of terms\n",
    "        terms += 1\n",
    "        \n",
    "        approx_error = approx_value\n",
    "        \n",
    "        # Calculate the approx value\n",
    "        approx_value = func(x, terms)\n",
    "        \n",
    "        # Calculate percentage approx error\n",
    "        approx_error = (approx_value - approx_error) / approx_value\n",
    "        approx_error *= 100\n",
    "        \n",
    "        # Printing\n",
    "        print(\"Number of terms: {}\".format(terms))\n",
    "        print(\"Approx value: {}\".format(approx_value))\n",
    "        print(\"Approx errror: {} %\\n\".format(abs(approx_error)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c377f58a",
   "metadata": {},
   "source": [
    "Once the function is defined, you can run that function to get the answer (as shown below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da1ff020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of terms: 1\n",
      "Approx value: 1.0\n",
      "Approx errror: -\n",
      "\n",
      "Number of terms: 2\n",
      "Approx value: 0.5558678019509788\n",
      "Approx errror: 79.89888899666624 %\n",
      "\n",
      "Number of terms: 3\n",
      "Approx value: 0.5887433701749547\n",
      "Approx errror: 5.5840235133699 %\n",
      "\n",
      "Number of terms: 4\n",
      "Approx value: 0.5877699636164597\n",
      "Approx errror: 0.1656101227945979 %\n",
      "\n",
      "Number of terms: 5\n",
      "Approx value: 0.5877854036591176\n",
      "Approx errror: 0.002626816277120294 %\n",
      "\n",
      "Number of terms: 6\n",
      "Approx value: 0.5877852512720046\n",
      "Approx errror: 2.592564420399015e-05 %\n",
      "\n",
      "Number of terms: 7\n",
      "Approx value: 0.5877852522974596\n",
      "Approx errror: 1.7446081526780443e-07 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "find_req_num_terms(maclaurin_cos, 0.3*math.pi, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df02ebd3",
   "metadata": {},
   "source": [
    "Numerical Differentiation\n",
    "----------------\n",
    "\n",
    "Use forward, backward, and central difference approximation for estimating the first derivative of \n",
    "\n",
    "$$\n",
    "    f(x) = -0.1x^{4} - 0.15x^{3} - 0.5x^{2} - 0.25x + 1.25\n",
    "$$\n",
    "\n",
    "at $x = 0.5$ using a step size $h = 0.5$.\n",
    "\n",
    "**Solution**: \n",
    "\n",
    "Following block of code defines function for computing various approximation and true value of derivative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d871297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_diff(x,h,func):\n",
    "    \"\"\"\n",
    "        Function for computing forward difference.\n",
    "        Input:\n",
    "        x - input at which derivative is desired\n",
    "        h - step size\n",
    "        func - python function which should return function value based on x.\n",
    "    \"\"\"\n",
    "    slope = (func(x+h) - func(x)) / h\n",
    "    return slope\n",
    "\n",
    "def backward_diff(x,h,func):\n",
    "    \"\"\"\n",
    "        Function for computing backward difference.\n",
    "        Input:\n",
    "        x - input at which derivative is desired\n",
    "        h - step size\n",
    "        func - python function which should return function value based on x.\n",
    "    \"\"\"\n",
    "    slope = (func(x) - func(x-h)) / h\n",
    "    return slope\n",
    "\n",
    "def central_diff(x,h,func):\n",
    "    \"\"\"\n",
    "        Function for computing central difference.\n",
    "        Input:\n",
    "        x - input at which derivative is desired\n",
    "        h - step size\n",
    "        func - python function which should return function value based on x.\n",
    "    \"\"\"\n",
    "    slope = (func(x+h) - func(x-h)) /2/h\n",
    "    return slope\n",
    "\n",
    "def true_function(x):\n",
    "    \"\"\"\n",
    "        Function which returns value of desired function at input x.\n",
    "    \"\"\"\n",
    "    return -0.1*x**4 - 0.15*x**3 - 0.5*x**2 - 0.25*x + 1.25\n",
    "\n",
    "def true_derivative(x):\n",
    "    \"\"\"\n",
    "        Returns true derivative of function at input x.\n",
    "    \"\"\"\n",
    "    return -0.4*x**3 - 0.45*x**2 - x - 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ff4254",
   "metadata": {},
   "source": [
    "Following block of code computes true and approximate value of derivate, and the error in the estimation using the functions defined in previous block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9149391",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'true_derivative' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# True value\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m true_value \u001b[38;5;241m=\u001b[39m \u001b[43mtrue_derivative\u001b[49m(x)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrue value: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(true_value))\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Forward difference\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'true_derivative' is not defined"
     ]
    }
   ],
   "source": [
    "# Few vairables\n",
    "x = 0.5\n",
    "h = 0.5\n",
    "\n",
    "# True value\n",
    "true_value = true_derivative(x)\n",
    "print(\"True value: {}\\n\".format(true_value))\n",
    "\n",
    "# Forward difference\n",
    "approx_value = forward_diff(x,h,true_function)\n",
    "print(\"Forward difference:\")\n",
    "print(\"Approx value: {}\".format(approx_value))\n",
    "print(\"True error: {}\\n\".format((true_value - approx_value)/true_value))\n",
    "\n",
    "# Backward difference\n",
    "approx_value = backward_diff(x,h,true_function)\n",
    "print(\"Backward difference:\")\n",
    "print(\"Approx value: {}\".format(approx_value))\n",
    "print(\"True error: {}\\n\".format((true_value - approx_value)/true_value))\n",
    "\n",
    "# Central difference\n",
    "approx_value = central_diff(x,h,true_function)\n",
    "print(\"Central difference:\")\n",
    "print(\"Approx value: {}\".format(approx_value))\n",
    "print(\"True error: {}\".format((true_value - approx_value)/true_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c95979",
   "metadata": {},
   "source": [
    "Now, we will check the variation of error based on the step size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a782286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_estimation(func,method,x,step_sizes):\n",
    "    \"\"\"\n",
    "        Function to compute error in the estimation for various step sizes\n",
    "        Input:\n",
    "        func - function which returns value of desired function at input x\n",
    "        method - function which returns derivative estimation at x\n",
    "        x - value at which derivative is required\n",
    "        step_sizes - 1d numpy array containing step sizes for derivative estimation\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initializing error array\n",
    "    error = np.zeros(len(step_sizes))\n",
    "    \n",
    "    # Computing error for the given step sizes\n",
    "    for index, step in enumerate(step_sizes):\n",
    "        true_value = true_derivative(x)\n",
    "        approx_value = method(x,step,func)\n",
    "        error[index] = abs((true_value - approx_value)/true_value)\n",
    "    \n",
    "    return error\n",
    "\n",
    "# Value at which derivative is required\n",
    "x = 0.5\n",
    "\n",
    "# Calculating step sizes\n",
    "initial_step = 0.5\n",
    "num_steps = 60\n",
    "step_sizes = np.zeros(num_steps)\n",
    "for i in range(num_steps):\n",
    "    step_sizes[i] = initial_step/(2**i)\n",
    "\n",
    "error_forward_diff = error_estimation(true_function,forward_diff,x,step_sizes)\n",
    "error_backward_diff = error_estimation(true_function,backward_diff,x,step_sizes)\n",
    "error_central_diff = error_estimation(true_function,central_diff,x,step_sizes)\n",
    "\n",
    "# Plotting the error variation with step sizes for different methods\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(step_sizes, error_forward_diff, label=\"Forward\", marker='.')\n",
    "ax.plot(step_sizes, error_backward_diff, label=\"Backward\", marker='.')\n",
    "ax.plot(step_sizes, error_central_diff, label=\"Central\", marker='.')\n",
    "ax.set_xscale('log')\n",
    "ax.invert_xaxis()\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel(\"Step size (h)\")\n",
    "ax.set_ylabel(\"Absolute value of true error\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2845ca68",
   "metadata": {},
   "source": [
    "As seen in the plot above, error in all the methods starts to increase after a specific step size. A more robust estimate of derivate can be obtained by using [complex-step method](https://blogs.mathworks.com/cleve/2013/10/14/complex-step-differentiation/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf95b96",
   "metadata": {},
   "source": [
    "Least-Squares Regresion\n",
    "------\n",
    "\n",
    "Data used in the problem is as follows:\n",
    "\n",
    "|x|y|\n",
    "|-|--|\n",
    "|1|1|\n",
    "|2|1.5|\n",
    "|3|2|\n",
    "|4|3|\n",
    "|5|4|\n",
    "|6|5|\n",
    "|7|8|\n",
    "|8|10|\n",
    "|9|13|\n",
    "\n",
    "First, we will compute mean, variance, standard deviation, coefficient of variation for $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d79d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "y = np.array([1, 1.5, 2, 3, 4, 5, 8, 10, 13])\n",
    "\n",
    "mean = np.mean(y)\n",
    "var = np.var(y)\n",
    "std_dev = np.std(y)\n",
    "coef_var = std_dev * 100 / mean \n",
    "\n",
    "print(\"Mean: {}\".format(mean))\n",
    "print(\"Variance: {}\".format(var))\n",
    "print(\"Standard deviation: {}\".format(std_dev))\n",
    "print(\"Coefficient of variation: {} %\".format(coef_var))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2de3f1",
   "metadata": {},
   "source": [
    "Following block defines a function to fit a straight line and second order polynomial to the data using least-squares method discussed in the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed4c63de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_line(x,y):\n",
    "    \"\"\"\n",
    "        Function which fits straight line to the data (x,y).\n",
    "        Input: \n",
    "        data x and y\n",
    "        Output:\n",
    "        Intercept (a0)\n",
    "        Slope (a1)\n",
    "        Standard error of fit (s_(y/x))\n",
    "        R_square (r^2)\n",
    "    \"\"\"\n",
    "    \n",
    "    num_pts = len(x) # Number of points\n",
    "    \n",
    "    # Computing intercept and slope\n",
    "    numerator = num_pts*np.sum(x*y) - np.sum(x)*np.sum(y)\n",
    "    denominator = num_pts*np.sum(x**2) - np.sum(x)**2\n",
    "    a1 = numerator/denominator\n",
    "    a0 = np.mean(y) - a1*np.mean(x)\n",
    "    \n",
    "    # Computing standard error in the fit\n",
    "    sum_error = 0\n",
    "    for index in range(num_pts):\n",
    "        sum_error = sum_error + (y[index] - a0 - a1*x[index])**2\n",
    "    std_error = np.sqrt(sum_error/(num_pts-2))\n",
    "    \n",
    "    # Computing r\n",
    "    numerator = num_pts*np.sum(x*y) - np.sum(x)*np.sum(y)\n",
    "    denominator = np.sqrt(num_pts*np.sum(x**2) - np.sum(x)**2) * np.sqrt(num_pts*np.sum(y**2) - np.sum(y)**2)\n",
    "    r = numerator/denominator\n",
    "        \n",
    "    return a0, a1, std_error, r**2\n",
    "\n",
    "def fit_polynomial(x,y):\n",
    "    \"\"\"\n",
    "        Function for fitting a polynomial to data\n",
    "    \"\"\"\n",
    "    \n",
    "    num_pts = len(x) # Number of points\n",
    "    \n",
    "    # Quantities need for calculation\n",
    "    mean_x = np.mean(x)\n",
    "    mean_y = np.mean(y)\n",
    "    sum_x = np.sum(x)\n",
    "    sum_x_square = np.sum(x**2)\n",
    "    sum_x_cube = np.sum(x**3)\n",
    "    sum_x_quartic = np.sum(x**4)\n",
    "    \n",
    "    # A matrix\n",
    "    A = np.array([[num_pts, sum_x, sum_x_square],\n",
    "                  [sum_x, sum_x_square, sum_x_cube],\n",
    "                  [sum_x_square, sum_x_cube, sum_x_quartic]])\n",
    "    \n",
    "    # B matrix\n",
    "    b = np.array([np.sum(y), np.sum(x*y), np.sum(x**2 * y)])\n",
    "    \n",
    "    # Solve the system of equation\n",
    "    solution = np.linalg.solve(A, b)\n",
    "    \n",
    "    # Computing standard error in the fit\n",
    "    sum_error = 0\n",
    "    for index in range(num_pts):\n",
    "        sum_error = sum_error + (y[index] - solution[0] - solution[1]*x[index] - solution[2]*x[index]**2)**2\n",
    "    std_error = np.sqrt(sum_error/(num_pts-3))\n",
    "    \n",
    "    # Computing r_square\n",
    "    r_square = 1 - sum_error/np.sum((y - np.mean(y))**2)\n",
    "    \n",
    "    return solution, std_error, r_square"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65f5f6b",
   "metadata": {},
   "source": [
    "Now, we will use the function defined in the previous block and fit a line and a second order polynomial to data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9dac9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the line\n",
    "a0, a1, std_error, r_square = fit_line(x,y)\n",
    "\n",
    "# Printing the result\n",
    "print(\"Fitting straight line to data:\")\n",
    "print(\"Slope: {}\".format(a0))\n",
    "print(\"Intercept: {}\".format(a1))\n",
    "print(\"Standard error: {}\".format(std_error))\n",
    "print(\"R square: {}\\n\".format(r_square))\n",
    "\n",
    "# Plotting the linear fit\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x,y,c=\"k\",label=\"data points\")\n",
    "ax.plot(np.linspace(1,9,50), a0 + a1*np.linspace(1,9,50), \"b\", label=\"linear fit\")\n",
    "\n",
    "# Fit the second-order polynomial\n",
    "solution, std_error, r_square = fit_polynomial(x,y)\n",
    "a0 = solution[0]\n",
    "a1 = solution[1]\n",
    "a2 = solution[2]\n",
    "\n",
    "# Printing the result\n",
    "print(\"Fitting second order polynomial to data:\")\n",
    "print(\"a0: {}\".format(a0))\n",
    "print(\"a1: {}\".format(a1))\n",
    "print(\"a2: {}\".format(a2))\n",
    "print(\"Standard error: {}\".format(std_error))\n",
    "print(\"R square: {}\\n\".format(r_square))\n",
    "\n",
    "# Plotting the polynomial fit\n",
    "ax.plot(np.linspace(1,9,50), a0 + a1*np.linspace(1,9,50) + a2*np.linspace(1,9,50)**2, \"r\", label=\"polynomial fit\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.legend(loc=\"lower right\")\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
