{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5481b3b9",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">AAE 590 Surrogate Methods</h1>\n",
    "\n",
    "## Design of Experiments\n",
    "\n",
    "This notebook supports material covered in the class for design of experiments. In this notebook, we will be using [`pyDOE2`](https://pythonhosted.org/pyDOE/) for generating samples. Following topics are covered:\n",
    "\n",
    "1. [Full Factorial Sampling](#Full-Factorial-Sampling)\n",
    "2. [Latin Squares Sampling](#Latin-Squares-Sampling)\n",
    "3. [Latin Hypercube Sampling](#Latin-Hypercube-Sampling)\n",
    "\n",
    "Before you proceed, you need to have `pyDOE2` package installed. If you don't have this package, then close jupyter notebook and install the package within the environment using `pip install pyDOE2` command in anaconda prompt.\n",
    "\n",
    "<font color='red'>**Please run the below block of code before you run any other block**</font> - it imports all the packages needed for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ef4fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyDOE2 import fullfact, lhs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import pdist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6526fd94",
   "metadata": {},
   "source": [
    "### Full Factorial Sampling\n",
    "\n",
    "First, we will look at full factorial sampling. You can read about how to use pyDOE2 for generating full-factorial samples in the [documentation](https://pythonhosted.org/pyDOE/factorial.html#general-full-factorial). Below block of code generates full-factorial samples for *two* dimensional problem and plots it. Read comments for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb5a430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining lower and upper bound\n",
    "# Number of entries in the array will be \n",
    "# equal to number of dimensions\n",
    "lb = np.array([-4, -4])\n",
    "ub = np.array([4, 4])\n",
    "\n",
    "# Defining number of samples to have in each dimension\n",
    "# Total number of samples will be product of number of\n",
    "# samples in each dimension\n",
    "levels = np.array([7, 7])\n",
    "\n",
    "# Generating nomralized sample. Note that the \n",
    "# output of `fullfact` is not between 0 and 1. So,\n",
    "# we have to normalize it.\n",
    "normalized_samples = fullfact(levels)/(levels-1)\n",
    "\n",
    "# Scaling the normalized samples\n",
    "samples = lb + (ub - lb)*normalized_samples\n",
    "\n",
    "# Plotting the samples\n",
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "ax.scatter(samples[:,0], samples[:,1])\n",
    "ax.set_xlabel(\"$X$\", fontsize=12)\n",
    "ax.set_ylabel(\"$Y$\", fontsize=12)\n",
    "ax.set_title(\"Samples\", fontsize=14)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00af9195",
   "metadata": {},
   "source": [
    "Now, we will generate full-factorial samples in *three* dimensions. Below block of code generates the samples and plots it. Read comments in the code for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c70f13",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Defining lower and upper bound\n",
    "# Number of entries in the array will be \n",
    "# equal to number of dimensions\n",
    "lb = np.array([-3, -1, -4])\n",
    "ub = np.array([1, 5, 4])\n",
    "\n",
    "# Defining number of samples to have in each dimension\n",
    "# Total number of samples will be product of number of\n",
    "# samples in each dimension\n",
    "levels = np.array([3,4,5])\n",
    "\n",
    "# Generating nomralized sample. Note that the \n",
    "# output of `fullfact` is not between 0 and 1. So,\n",
    "# we have to normalize it.\n",
    "normalized_samples = fullfact(levels)/(levels-1)\n",
    "\n",
    "# Scaling the normalized samples\n",
    "samples = lb + (ub - lb)*normalized_samples\n",
    "\n",
    "# Plotting the samples\n",
    "fig = plt.figure(figsize=(7,6))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter3D(samples[:,0], samples[:,1], samples[:,2], color=\"k\")\n",
    "ax.set_xlabel('X-axis')\n",
    "ax.set_ylabel('Y-axis')\n",
    "ax.set_zlabel('Z-axis')\n",
    "\n",
    "# Plotting X and Y\n",
    "fig, ax = plt.subplots(figsize=(5,4))\n",
    "ax.scatter(samples[:,0], samples[:,1])\n",
    "ax.set_xlabel(\"$X$\", fontsize=12)\n",
    "ax.set_ylabel(\"$Y$\", fontsize=12)\n",
    "ax.set_title(\"Samples\", fontsize=14)\n",
    "ax.grid()\n",
    "\n",
    "# Plotting Y and Z\n",
    "fig, ax = plt.subplots(figsize=(5,4))\n",
    "ax.scatter(samples[:,1], samples[:,2])\n",
    "ax.set_xlabel(\"$Y$\", fontsize=12)\n",
    "ax.set_ylabel(\"$Z$\", fontsize=12)\n",
    "ax.set_title(\"Samples\", fontsize=14)\n",
    "ax.grid()\n",
    "\n",
    "# Plotting X and Z\n",
    "fig, ax = plt.subplots(figsize=(5,4))\n",
    "ax.scatter(samples[:,0], samples[:,2])\n",
    "ax.set_xlabel(\"$X$\", fontsize=12)\n",
    "ax.set_ylabel(\"$Z$\", fontsize=12)\n",
    "ax.set_title(\"Samples\", fontsize=14)\n",
    "ax.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a21bfe",
   "metadata": {},
   "source": [
    "### Latin Squares Sampling\n",
    "\n",
    "Now, we will look into latin squares sampling i.e. two dimensional latin hypercube sampling. `lhs` function within pyDOE2 generates latin hypercube samples. We will generate two different kinds of samples - *random* and *centermaximin*.  Important parameter in the `lhs` function which determines sampling type is `criterion`. If it is kept as `None`, then random lhs samples will be generated. If it is set to `centermaximin`, then it will generate sample using some heuristics to increase the minimum distance between the points. You can read about how to use pyDOE2 for generating lhs samples in the [documentation](https://pythonhosted.org/pyDOE/randomized.html#latin-hypercube).\n",
    "\n",
    "Below block of code generates different sizes of random lhs samples for **two dimensional problem**, computes minimum distance between the points and plots the points using `seaborn`. Read comments for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eadb43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Defining lower and upper bound\n",
    "# Number of entries in the array will be \n",
    "# equal to number of dimensions\n",
    "lb = np.array([-2, -3])\n",
    "ub = np.array([5, 3])\n",
    "\n",
    "# Number of variables\n",
    "dim = len(lb)\n",
    "\n",
    "# Generate random lhs samples of size 5, 25, 125, and 625\n",
    "for itr in range(4):\n",
    "    # Total number of samples\n",
    "    num_samples = 5**(itr+1)\n",
    "    \n",
    "    # Generating samples. Output will be normalized\n",
    "    # We are fixing the random state so that we can\n",
    "    # compare with different criterion. But, in general,\n",
    "    # you don't have to set randome state\n",
    "    normalized_samples = lhs(dim, num_samples, iterations=10000, random_state=56, criterion=None)\n",
    "\n",
    "    # Scaling the normalized variables\n",
    "    samples = lb + (ub - lb)*normalized_samples\n",
    "    \n",
    "    # Computing the minimum distance between all the samples\n",
    "    min_dist = np.min(pdist(samples))\n",
    "    \n",
    "    # Print the minimum distance\n",
    "    print(\"Minimum distance between the {} samples: {}\".format(num_samples, min_dist))\n",
    "\n",
    "    # Plotting the samples using seaborn\n",
    "    sns.jointplot(x=samples[:,0], y=samples[:,1])\n",
    "    plt.xlabel(\"$X$\", fontsize=12)\n",
    "    plt.ylabel(\"$Y$\", fontsize=12)\n",
    "    plt.xlim(left=lb[0], right=ub[0])\n",
    "    plt.ylim(bottom=lb[1], top=ub[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e653ce54",
   "metadata": {},
   "source": [
    "Note that minimum distance between the samples decrease as you increase the number of points (obviously). Also, the distribution of samples approach uniform distribution which denotes that samples are equally likely in the given interval. Now, we will change the criteria and see if it increases the minimum distance between the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622ef4b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Defining lower and upper bound\n",
    "# Number of entries in the array will be \n",
    "# equal to number of dimensions\n",
    "lb = np.array([-2, -3])\n",
    "ub = np.array([5, 3])\n",
    "\n",
    "# Number of variables\n",
    "dim = len(lb)\n",
    "\n",
    "# Generate random lhs samples of size 5, 25, 125, and 625\n",
    "for itr in range(4):\n",
    "    # Total number of samples\n",
    "    num_samples = 5**(itr+1)\n",
    "    \n",
    "    # Generating samples. Output will be normalized\n",
    "    normalized_samples = lhs(dim, num_samples, iterations=10000, random_state=56, criterion=\"centermaximin\")\n",
    "\n",
    "    # Scaling the normalized variables\n",
    "    samples = lb + (ub - lb)*normalized_samples\n",
    "    \n",
    "    # Computing the minimum distance between all the samples\n",
    "    min_dist = np.min(pdist(samples))\n",
    "    \n",
    "    # Print the minimum distance\n",
    "    print(\"Minimum distance between the {} samples: {}\".format(num_samples, min_dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bccca3b",
   "metadata": {},
   "source": [
    "The minimum distance in this case is higher than the case of random lhs sampling. This shows that pyDOE2 is using some hueristics to increase the minimum distance. **Note**: This is not space-filling lhs which actually involves an optimization problem. Now, we will generate samples in higher dimensions.\n",
    "\n",
    "### Latin Hypercube Sampling\n",
    "\n",
    "The process to generate samples is similar to what is described in previous section. In this section, we will generate samples in four dimensions. Samples of different size are generated and minimum distance between the points is also calculated. Plotting of points is done using `pairplot` within seaborn. You can refer [tutorial section](https://seaborn.pydata.org/tutorial/distributions.html#plotting-many-distributions) of seaborn for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69ca0c5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Defining lower and upper bound\n",
    "# Number of entries in the array will be \n",
    "# equal to number of dimensions\n",
    "lb = np.array([-2, -3, -3, -4])\n",
    "ub = np.array([5, 3, 4, 5])\n",
    "\n",
    "# Number of variables\n",
    "dim = len(lb)\n",
    "\n",
    "# Generate random lhs samples of size 5, 25, 125, and 625\n",
    "for itr in range(4):\n",
    "    # Total number of samples\n",
    "    num_samples = 5**(itr+1)\n",
    "    \n",
    "    # Generating samples. Output will be normalized\n",
    "    normalized_samples = lhs(dim, num_samples, iterations=100, random_state=56, criterion=None)\n",
    "\n",
    "    # Scaling the normalized variables\n",
    "    samples = lb + (ub - lb)*normalized_samples\n",
    "    \n",
    "    # Computing the minimum distance between all the samples\n",
    "    min_dist = np.min(pdist(samples))\n",
    "    \n",
    "    print(\"Minimum distance between the {} samples: {}\".format(num_samples, min_dist))\n",
    "\n",
    "    # Creating a pandas dataframe for plotting\n",
    "    df = pd.DataFrame(samples, columns = ['A','B','C','D'])\n",
    "    \n",
    "    # Plotting the samples\n",
    "    sns.pairplot(data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9695181f",
   "metadata": {},
   "source": [
    "As mentioned earlier, minimum distance between the samples decrease as you increase the number of points. Diagonal plots show the distribution of samples and you can see that distribution approaches uniform distribution which denotes that samples are equally likely in the given interval. All off-diagonal plots show the distribution of points between any two variables.\n",
    "\n",
    "Now, we will change the criteria and see if it increases the minimum distance between the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844c1ffa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Defining lower and upper bound\n",
    "# Number of entries in the array will be \n",
    "# equal to number of dimensions\n",
    "lb = np.array([-2, -3, -3, -4])\n",
    "ub = np.array([5, 3, 4, 5])\n",
    "\n",
    "# Number of variables\n",
    "dim = len(lb)\n",
    "\n",
    "# Generate random lhs samples of size 5, 25, 125, and 625\n",
    "for itr in range(4):\n",
    "    # Total number of samples\n",
    "    num_samples = 5**(itr+1)\n",
    "    \n",
    "    # Generating samples. Output will be normalized\n",
    "    normalized_samples = lhs(dim, num_samples, iterations=100, random_state=56, criterion=\"centermaximin\")\n",
    "\n",
    "    # Scaling the normalized variables\n",
    "    samples = lb + (ub - lb)*normalized_samples\n",
    "    \n",
    "    # Computing the minimum distance between all the samples\n",
    "    min_dist = np.min(pdist(samples))\n",
    "    \n",
    "    print(\"Minimum distance between the {} samples: {}\".format(num_samples, min_dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b19d48",
   "metadata": {},
   "source": [
    "The minimum distance in this case is higher than the case of random lhs sampling. This shows that pyDOE2 is using some hueristics to increase the minimum distance. **Note**: This is not space-filling lhs which actually involves an optimization problem. Now, we will gnereate samples in higher dimensions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
