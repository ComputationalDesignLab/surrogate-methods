
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Sequential Sampling using Dimensionality Reduction &#8212; Surrogate Methods</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css?v=6644e6bb" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=87e54e7c" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'dim_reduction/seq_sampling';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
  
    <p class="title logo__title">Surrogate Methods</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    Introduction
                </a>
            </li>
        </ul>
        <ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../setup.html">Computing environment setup</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../python_basics/intro.html">Basics of Python Programming</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../python_basics/python_basics.html">Basic programming in Python and Jupyter Notebooks</a></li>






<li class="toctree-l2"><a class="reference internal" href="../python_basics/torch_basics.html">Basics of PyTorch tensor computations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python_basics/plotting.html">Basic plotting in Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python_basics/resources.html">Python and Jupyter notebook resources</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../doe.html">Sampling Plans</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/ComputationalDesignLab/surrogate-methods" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/dim_reduction/seq_sampling.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Sequential Sampling using Dimensionality Reduction</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sequential-sampling-using-expected-improvement-ei">Sequential Sampling using Expected Improvement (EI)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sequential-sampling-using-pricinpal-component-analysis-and-ei-pca-ei">Sequential Sampling using Pricinpal Component Analysis and EI (PCA-EI)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sequential-sampling-using-kernel-pca-and-ei-kpca-ei">Sequential Sampling using Kernel PCA and EI (KPCA-EI)</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="sequential-sampling-using-dimensionality-reduction">
<h1>Sequential Sampling using Dimensionality Reduction<a class="headerlink" href="#sequential-sampling-using-dimensionality-reduction" title="Link to this heading">#</a></h1>
<p>This section provides an example implementation of the usage of dimensionality reduction along with expected improvement (EI) to perform exploration and exploitation of a high-dimensional function. The dimensionality reduction methods used in this section are principal component analysis (PCA) and kernel principal component analysis. The example problem used to demonstrate sequential sampling using dimensionality reduction is the 10-dimensional Styblinski-Tang function. The problem statement can be written as</p>
<div class="math notranslate nohighlight">
\[f(\textbf{x}) = \frac{1}{2} \sum_{i=1}^{10} (x_i^4 - 16x_i^2 + 5x_i)\]</div>
<div class="math notranslate nohighlight">
\[ -5 \leq x_i \leq 5, \quad i = 1,...,10 \]</div>
<p>The global minimum of the function is <span class="math notranslate nohighlight">\(f(\textbf{x}^*)=-391.6599\)</span> at <span class="math notranslate nohighlight">\(\textbf{x}^*=(-2.904,...,-2.904)\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imports</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.decomposition</span><span class="w"> </span><span class="kn">import</span> <span class="n">PCA</span><span class="p">,</span> <span class="n">KernelPCA</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">smt.surrogate_models</span><span class="w"> </span><span class="kn">import</span> <span class="n">KRG</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">smt.sampling_methods</span><span class="w"> </span><span class="kn">import</span> <span class="n">LHS</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pymoo.core.problem</span><span class="w"> </span><span class="kn">import</span> <span class="n">Problem</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pymoo.algorithms.soo.nonconvex.de</span><span class="w"> </span><span class="kn">import</span> <span class="n">DE</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pymoo.optimize</span><span class="w"> </span><span class="kn">import</span> <span class="n">minimize</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pymoo.config</span><span class="w"> </span><span class="kn">import</span> <span class="n">Config</span>
<span class="n">Config</span><span class="o">.</span><span class="n">warnings</span><span class="p">[</span><span class="s1">&#39;not_compiled&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">norm</span> <span class="k">as</span> <span class="n">normal</span>
</pre></div>
</div>
</div>
</div>
<p>The block of code below defines the Styblinski-Tang function for any number of dimensions. We will be using the 10-dimensional version of the function and therefore, need to provide a 10-dimensional input to this function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Styblinski-Tang function</span>
<span class="k">def</span><span class="w"> </span><span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function which calculates the Styblinski-Tang function value at given x.</span>
<span class="sd">        </span>
<span class="sd">        Input:</span>
<span class="sd">        x - 1D/2D numpy array</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Number of dimensions of input</span>
    <span class="n">dim</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">ndim</span>

    <span class="c1"># To ensure n x 2</span>
    <span class="k">if</span> <span class="n">dim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">innersum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">3</span><span class="p">))</span>

    <span class="n">innersum</span><span class="p">[:,:,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="o">**</span><span class="mi">4</span>
    <span class="n">innersum</span><span class="p">[:,:,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">16</span><span class="o">*</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span>
    <span class="n">innersum</span><span class="p">[:,:,</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">5</span><span class="o">*</span><span class="n">x</span>

    <span class="n">outersum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">innersum</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    
    <span class="n">y</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">outersum</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">dim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,)</span>
    
    <span class="k">return</span> <span class="n">y</span>
</pre></div>
</div>
</div>
</div>
<section id="sequential-sampling-using-expected-improvement-ei">
<h2>Sequential Sampling using Expected Improvement (EI)<a class="headerlink" href="#sequential-sampling-using-expected-improvement-ei" title="Link to this heading">#</a></h2>
<p>The blocks of code below will perform sequential sampling using the standard EI that was demonstrated in the Sequential Sampling section of the Jupyter Book. The random state for the generation of initial samples is fixed since the results obtained using EI will be compared to those obtained using the dimensionality reduction methods and therefore, it is important for each of the algorithms to start with the same initial samples. However, the results can still vary if the sequential sampling is re-run since the seed for differential evolution has not been set. For a fair comparison, the convergence criterion of the sampling is set as the maximum number of iterations. This is so that EI and the other methods will run for the same number of iterations and perform the same number of infills. In the end, the best objective value can be compared to compare the performance of the algorithms. As you will observe, it is also quite difficult for the max EI to meet the convergence criteria for a high-dimensional function. In such cases, the aim is to obtain the best possible value of the objective function in the shortest amount of sampling iterations.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Setting number of dimensions for the problem - 10D Styblinski-Tang Function</span>
<span class="n">ndim</span> <span class="o">=</span> <span class="mi">10</span>

<span class="c1"># Defining bounds</span>
<span class="n">lb</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">5</span><span class="p">]</span><span class="o">*</span><span class="n">ndim</span><span class="p">)</span>
<span class="n">ub</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">5</span><span class="p">]</span><span class="o">*</span><span class="n">ndim</span><span class="p">)</span>
    
<span class="c1"># Problem class</span>
<span class="k">class</span><span class="w"> </span><span class="nc">EI</span><span class="p">(</span><span class="n">Problem</span><span class="p">):</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sm</span><span class="p">,</span> <span class="n">ymin</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">n_var</span><span class="o">=</span><span class="n">ndim</span><span class="p">,</span> <span class="n">n_obj</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_constr</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">xl</span><span class="o">=</span><span class="n">lb</span><span class="p">,</span> <span class="n">xu</span><span class="o">=</span><span class="n">ub</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">sm</span> <span class="o">=</span> <span class="n">sm</span> <span class="c1"># store the surrogate model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ymin</span> <span class="o">=</span> <span class="n">ymin</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>

        <span class="c1"># Standard normal</span>
        <span class="n">numerator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ymin</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">sm</span><span class="o">.</span><span class="n">predict_values</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">denominator</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">sm</span><span class="o">.</span><span class="n">predict_variances</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">numerator</span> <span class="o">/</span> <span class="n">denominator</span>
        
        <span class="c1"># Computing expected improvement</span>
        <span class="c1"># Negative sign because we want to maximize EI</span>
        <span class="n">out</span><span class="p">[</span><span class="s2">&quot;F&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span> <span class="p">(</span> <span class="n">numerator</span> <span class="o">*</span> <span class="n">normal</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">z</span><span class="p">)</span> <span class="o">+</span> <span class="n">denominator</span> <span class="o">*</span> <span class="n">normal</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">z</span><span class="p">)</span> <span class="p">)</span>

<span class="c1"># Optimization algorithm</span>
<span class="n">algorithm</span> <span class="o">=</span> <span class="n">DE</span><span class="p">(</span><span class="n">pop_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">CR</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">dither</span><span class="o">=</span><span class="s2">&quot;vector&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The block of code below creates 20 training points and performs the sequential sampling process using EI. The convergence criterion is set at a maximum number of 45 iterations.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Setting a random state to allow a fair comparison between the different methods</span>
<span class="n">random_state</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">xlimits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">lb</span><span class="p">,</span><span class="n">ub</span><span class="p">))</span>
<span class="n">sampler</span> <span class="o">=</span> <span class="n">LHS</span><span class="p">(</span><span class="n">xlimits</span><span class="o">=</span><span class="n">xlimits</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="s1">&#39;ese&#39;</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">20</span><span class="p">)</span>

<span class="c1"># Training data</span>
<span class="n">num_train</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">xtrain</span> <span class="o">=</span> <span class="n">sampler</span><span class="p">(</span><span class="n">num_train</span><span class="p">)</span>
<span class="n">ytrain</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">xtrain</span><span class="p">)</span>

<span class="c1"># Variables</span>
<span class="n">itr</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">max_itr</span> <span class="o">=</span> <span class="mi">45</span>
<span class="n">tol</span> <span class="o">=</span> <span class="mf">1e-3</span>
<span class="n">max_EI</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">ybest</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">corr</span> <span class="o">=</span> <span class="s1">&#39;squar_exp&#39;</span>
<span class="n">fs</span> <span class="o">=</span> <span class="mi">12</span>

<span class="c1"># Sequential sampling Loop</span>
<span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="k">while</span> <span class="n">itr</span> <span class="o">&lt;</span> <span class="n">max_itr</span><span class="p">:</span>
        
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Iteration </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">itr</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>

    <span class="c1"># Initializing the kriging model</span>
    <span class="n">sm</span> <span class="o">=</span> <span class="n">KRG</span><span class="p">(</span><span class="n">theta0</span><span class="o">=</span><span class="p">[</span><span class="mf">1e-2</span><span class="p">],</span> <span class="n">corr</span><span class="o">=</span><span class="n">corr</span><span class="p">,</span> <span class="n">theta_bounds</span><span class="o">=</span><span class="p">[</span><span class="mf">1e-6</span><span class="p">,</span> <span class="mf">1e2</span><span class="p">],</span> <span class="n">print_global</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># Setting the training values</span>
    <span class="n">sm</span><span class="o">.</span><span class="n">set_training_values</span><span class="p">(</span><span class="n">xtrain</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">)</span>
    
    <span class="c1"># Creating surrogate model</span>
    <span class="n">sm</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

    <span class="c1"># Find the best observed sample</span>
    <span class="n">ybest</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">ytrain</span><span class="p">))</span>

    <span class="c1"># Find the minimum of surrogate model</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">EI</span><span class="p">(</span><span class="n">sm</span><span class="p">,</span> <span class="n">ybest</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">algorithm</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    
    <span class="c1"># Computing true function value at infill point</span>
    <span class="n">y_infill</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

    <span class="c1"># Storing variables</span>
    <span class="k">if</span> <span class="n">itr</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">max_EI</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">result</span><span class="o">.</span><span class="n">F</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">xbest</span> <span class="o">=</span> <span class="n">xtrain</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">ytrain</span><span class="p">)]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">max_EI</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="o">-</span><span class="n">result</span><span class="o">.</span><span class="n">F</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">xbest</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">xbest</span><span class="p">,</span> <span class="n">xtrain</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">ytrain</span><span class="p">)]))</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Maximum EI: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">max_EI</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best observed value: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ybest</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>

    <span class="c1"># Appending the the new point to the current data set</span>
    <span class="n">xtrain</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span> <span class="n">xtrain</span><span class="p">,</span> <span class="n">result</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="p">))</span>
    <span class="n">ytrain</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="n">ytrain</span><span class="p">,</span> <span class="n">y_infill</span> <span class="p">)</span>
    
    <span class="n">itr</span> <span class="o">=</span> <span class="n">itr</span> <span class="o">+</span> <span class="mi">1</span> <span class="c1"># Increasing the iteration number</span>

<span class="n">t2</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="c1"># Printing the final results</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Best obtained point:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;x*: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">xbest</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;f*: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ybest</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>

<span class="c1"># Storing results</span>
<span class="n">ei_ybest</span> <span class="o">=</span> <span class="n">ybest</span>
<span class="n">ei_xbest</span> <span class="o">=</span> <span class="n">xbest</span>
<span class="n">ei_time</span> <span class="o">=</span> <span class="n">t2</span> <span class="o">-</span> <span class="n">t1</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Iteration 1
Maximum EI: 29.9348389478
Best observed value: -150.53602901269912

Iteration 2
Maximum EI: 14.313598360026237
Best observed value: -150.53602901269912

Iteration 3
Maximum EI: 22.179316153376632
Best observed value: -150.53602901269912

Iteration 4
Maximum EI: 47.68078740723258
Best observed value: -150.53602901269912

Iteration 5
Maximum EI: 27.92762674314964
Best observed value: -150.53602901269912

Iteration 6
Maximum EI: 35.52459213127647
Best observed value: -150.53602901269912

Iteration 7
Maximum EI: 21.340778116409087
Best observed value: -192.73791154099587

Iteration 8
Maximum EI: 31.383882396972645
Best observed value: -192.73791154099587

Iteration 9
Maximum EI: 100.85633714502279
Best observed value: -192.73791154099587

Iteration 10
Maximum EI: 122.32202034153798
Best observed value: -192.73791154099587

Iteration 11
Maximum EI: 80.8309296006207
Best observed value: -192.73791154099587

Iteration 12
Maximum EI: 31.260095296453123
Best observed value: -192.73791154099587

Iteration 13
Maximum EI: 151.88959638844773
Best observed value: -192.73791154099587

Iteration 14
Maximum EI: 157.57438822132775
Best observed value: -192.73791154099587

Iteration 15
Maximum EI: 35.026518026884695
Best observed value: -253.5774800946036

Iteration 16
Maximum EI: 40.05880408843345
Best observed value: -253.5774800946036

Iteration 17
Maximum EI: 58.57645237370734
Best observed value: -253.5774800946036

Iteration 18
Maximum EI: 19.833993204779233
Best observed value: -253.5774800946036

Iteration 19
Maximum EI: 53.998707036136615
Best observed value: -253.5774800946036

Iteration 20
Maximum EI: 35.433099424032086
Best observed value: -253.5774800946036

Iteration 21
Maximum EI: 141.66355228032603
Best observed value: -253.5774800946036

Iteration 22
Maximum EI: 61.554321842411575
Best observed value: -253.5774800946036

Iteration 23
Maximum EI: 24.163608795294632
Best observed value: -253.5774800946036

Iteration 24
Maximum EI: 34.46314298786474
Best observed value: -253.5774800946036

Iteration 25
Maximum EI: 47.58428938642727
Best observed value: -253.5774800946036

Iteration 26
Maximum EI: 73.62714098837189
Best observed value: -253.5774800946036

Iteration 27
Maximum EI: 65.15735444189076
Best observed value: -253.5774800946036

Iteration 28
Maximum EI: 35.8420833840719
Best observed value: -253.5774800946036

Iteration 29
Maximum EI: 40.774785212229574
Best observed value: -253.5774800946036

Iteration 30
Maximum EI: 105.86959520012738
Best observed value: -253.5774800946036

Iteration 31
Maximum EI: 26.743519409189027
Best observed value: -253.5774800946036

Iteration 32
Maximum EI: 59.27164708421749
Best observed value: -253.5774800946036

Iteration 33
Maximum EI: 16.777867763941636
Best observed value: -253.5774800946036

Iteration 34
Maximum EI: 103.14344593068768
Best observed value: -253.5774800946036

Iteration 35
Maximum EI: 38.507210472613274
Best observed value: -253.5774800946036

Iteration 36
Maximum EI: 83.84116152222884
Best observed value: -253.5774800946036

Iteration 37
Maximum EI: 45.98842872492748
Best observed value: -253.5774800946036

Iteration 38
Maximum EI: 40.16082675619078
Best observed value: -253.5774800946036

Iteration 39
Maximum EI: 59.16649503409608
Best observed value: -253.5774800946036

Iteration 40
Maximum EI: 60.47936286860907
Best observed value: -253.5774800946036

Iteration 41
Maximum EI: 45.26394341491553
Best observed value: -253.5774800946036

Iteration 42
Maximum EI: 17.117510644528192
Best observed value: -253.5774800946036

Iteration 43
Maximum EI: 14.92894101279543
Best observed value: -253.5774800946036

Iteration 44
Maximum EI: 42.15794217533398
Best observed value: -253.5774800946036

Iteration 45
Maximum EI: 19.85722675846832
Best observed value: -253.5774800946036

Best obtained point:
x*: [-1.40635186 -2.74523788 -2.42496525 -0.71897207 -1.25984989 -2.97299565
 -1.70697381 -2.84230564 -2.82505042 -0.17037821]
f*: -253.5774800946036
</pre></div>
</div>
</div>
</div>
<p>The block of code below will plot the history of the best observed value of the objective function against the number of iterations.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plotting variation of best value of objective function</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">itr</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">ei_ybest</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;blue&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;EI&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Iterations&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Best observed $f^*$&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span> <span class="o">=</span> <span class="mi">14</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="n">itr</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/7ccb07ef3c33b6ad703c27137a53a6f07511d56935c35da5f0770d3c533e0cdc.png" src="../_images/7ccb07ef3c33b6ad703c27137a53a6f07511d56935c35da5f0770d3c533e0cdc.png" />
</div>
</div>
<p>The results of EI show that the sequential sampling algorithm is not able to find the global optimum of the function even after the addition of 45 infill samples. This is demonstrative of the difficulty of optimizing high-dimensional functions using surrogate-based methods. However, the algorithm is able to decrease the best observed value of the function from aporoximately -150 to approximately -253. Now, the same problem will be solved using dimensionality reduction methods to demonstrate the improvements that can be seen while optimizing high-dimensional functions.</p>
</section>
<section id="sequential-sampling-using-pricinpal-component-analysis-and-ei-pca-ei">
<h2>Sequential Sampling using Pricinpal Component Analysis and EI (PCA-EI)<a class="headerlink" href="#sequential-sampling-using-pricinpal-component-analysis-and-ei-pca-ei" title="Link to this heading">#</a></h2>
<p>The blocks of code below will demonstrate the use of PCA along with EI to optimize the function using sequential sampling. The main idea here is to reduce the dimensionality of the input data from 10 to 5 using PCA. The 5 principal components obtained in this manner will be the new design variables for the problem. The kriging model will use the principal components as the input data and the original function values as the output data. Essentially, this means that we will be solving a new optimization problem that has lower dimensionality than the original 10-dimensional problem. In this case, the optimization problem statement for maximizing EI has to be redefined as</p>
<div class="math notranslate nohighlight">
\[\begin{split}\underset{\xi}{\max} \text{PEI}(\xi) = \begin{cases} 
      \text{EI}(\xi) &amp; \xi \; \textrm{is feasible}\\
      -P &amp; \xi \; \textrm{is infeasible}
   \end{cases}
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[ \min(\xi_i) \leq \xi_i \leq \max(\xi_i), \quad i = 1,...,5 \]</div>
<p>where <span class="math notranslate nohighlight">\(\xi\)</span> represents the principal components found using PCA and <span class="math notranslate nohighlight">\(\text{PEI}(\xi)\)</span> represents the penalized version of EI. The bounds for the maximization are the maximum and minimum values of <span class="math notranslate nohighlight">\(\xi\)</span> that are found using the sampling plan at a given iteration of the sequential sampling algorithm. Even though bounds are placed on the low-dimensional representation of the problem using the minimum and maximum values of the principal components, the usage of penalized expected improvement is required since it is not known that the point evaluated by differential evolution while maximizing the penalized EI actually lies within the bounds of the original problem. It is, therefore, necessary to penalize the points that are outside of the original bounds of the problem. At each evaluation of the objective in differential evolution, the principal components are transformed back to the original high-dimensional space and a check is performed to determine if the point being evaluated is within the bounds of the original problem or not. If it is within the original bounds, then the objective returns the standard EI otherwise it will return a large value as a penalty. In this case, the penalty, P, is a fixed value of 1000, however, more intricate implementations could vary the penalty based on the point in the design space being evaluated.</p>
<p>Additionally, an important parameter for PCA is the number of principal components to use, which must be selected by the user. To determine the correct number of principal components, the cumulative explained variance ratio plot described in the previous section can be used. The block of code below plots the cumulative explained variance ratio plot for the 10-dimensional Styblinksi-Tang function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generating data</span>
<span class="n">xlimits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">lb</span><span class="p">,</span><span class="n">ub</span><span class="p">))</span>
<span class="n">random_state</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">sampler</span> <span class="o">=</span> <span class="n">LHS</span><span class="p">(</span><span class="n">xlimits</span><span class="o">=</span><span class="n">xlimits</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="s1">&#39;ese&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>

<span class="n">num_train</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">xtrain</span> <span class="o">=</span> <span class="n">sampler</span><span class="p">(</span><span class="n">num_train</span><span class="p">)</span>
<span class="n">ytrain</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">xtrain</span><span class="p">)</span>

<span class="c1"># Pre-processing data before applying PCA</span>
<span class="n">center</span> <span class="o">=</span> <span class="n">xtrain</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">xtrain_center</span> <span class="o">=</span> <span class="n">xtrain</span> <span class="o">-</span> <span class="n">center</span>

<span class="c1"># Calculating sum of explained variance ratios</span>
<span class="n">sum_explained_variance_ratio_</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">n_components</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">ndim</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>

<span class="k">for</span> <span class="n">component</span> <span class="ow">in</span> <span class="n">n_components</span><span class="p">:</span>
    <span class="c1"># Applying PCA to the data</span>
    <span class="n">transform</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">component</span><span class="p">)</span>
    <span class="n">xprime</span> <span class="o">=</span> <span class="n">transform</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">xtrain_center</span><span class="p">)</span>
    <span class="n">sum_explained_variance_ratio_</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">transform</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">))</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">n_components</span><span class="p">,</span> <span class="n">sum_explained_variance_ratio_</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Number of Principal Components&#39;</span><span class="p">,</span> <span class="n">fontsize</span> <span class="o">=</span> <span class="mi">14</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Cumulative Explained Variance Ratio&#39;</span><span class="p">,</span> <span class="n">fontsize</span> <span class="o">=</span> <span class="mi">14</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0, 0.5, &#39;Cumulative Explained Variance Ratio&#39;)
</pre></div>
</div>
<img alt="../_images/35e1332d5b294a62ea01e640de9d8d40ea21aa74e2f5474324fe0855281bb749.png" src="../_images/35e1332d5b294a62ea01e640de9d8d40ea21aa74e2f5474324fe0855281bb749.png" />
</div>
</div>
<p>The above plot of the cumulative explained variance ratio shows that the cumulative explained variance ratio increases linearly with the number of principal components. This suggests that each of the design variables explains an equal ratio of the variance of the objective function and to satisfy a threshold of 95% cumulative explained variance ratio it will be necessary to select all of the principal components. However, in order to demonstrate the use of dimensionality reduction, five principal components are chosen to represent the objective function. This allows the representation of at least 50% of the variance in the objective which is enough to aid in optimizing the objective function of interest for this section. This will be made clear in the results of the sequential sampling that follow.</p>
<p>To begin the implementation of sequential sampling using PCA and EI, the block of code below defines the Problem class and differential evolution algorithm for the penalized EI that is to be used for sequential sampling using dimensionality reduction.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Problem class</span>
<span class="c1"># Upper bound, lower bound and number of variables are added as parameters</span>
<span class="k">class</span><span class="w"> </span><span class="nc">EI_DR</span><span class="p">(</span><span class="n">Problem</span><span class="p">):</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sm</span><span class="p">,</span> <span class="n">ymin</span><span class="p">,</span> <span class="n">lb</span><span class="p">,</span> <span class="n">ub</span><span class="p">,</span> <span class="n">n_var</span><span class="p">,</span> <span class="n">pca</span><span class="p">,</span> <span class="n">center</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">n_var</span><span class="o">=</span><span class="n">n_var</span><span class="p">,</span> <span class="n">n_obj</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_constr</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">xl</span><span class="o">=</span><span class="n">lb</span><span class="p">,</span> <span class="n">xu</span><span class="o">=</span><span class="n">ub</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">sm</span> <span class="o">=</span> <span class="n">sm</span> <span class="c1"># store the surrogate model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ymin</span> <span class="o">=</span> <span class="n">ymin</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pca</span> <span class="o">=</span> <span class="n">pca</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">center</span> <span class="o">=</span> <span class="n">center</span>
        
    <span class="k">def</span><span class="w"> </span><span class="nf">expected_improvement</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        
        <span class="n">numerator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ymin</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">sm</span><span class="o">.</span><span class="n">predict_values</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">denominator</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span> <span class="bp">self</span><span class="o">.</span><span class="n">sm</span><span class="o">.</span><span class="n">predict_variances</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">numerator</span> <span class="o">/</span> <span class="n">denominator</span>
        
        <span class="k">return</span> <span class="n">numerator</span> <span class="o">*</span> <span class="n">normal</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">z</span><span class="p">)</span> <span class="o">+</span> <span class="n">denominator</span> <span class="o">*</span> <span class="n">normal</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">penalized_expected_improvement</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        
        <span class="c1"># map back the candidate point to check if it falls inside the original domain</span>
        <span class="n">x_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pca</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">center</span>
        <span class="n">idx_lower</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x_</span> <span class="o">&lt;</span> <span class="o">-</span><span class="mf">5.0</span><span class="p">)</span>
        <span class="n">idx_lower</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">idx_lower</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">idx_lower</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
        <span class="n">idx_upper</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x_</span> <span class="o">&gt;</span> <span class="mf">5.0</span><span class="p">)</span>
        <span class="n">idx_upper</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">idx_upper</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">idx_upper</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
        
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">expected_improvement</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="c1"># Assigning a high valued penalty for points that are outside the original bounds of the </span>
        <span class="c1"># problem</span>
        <span class="n">out</span><span class="p">[</span><span class="n">idx_lower</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1000</span>
        <span class="n">out</span><span class="p">[</span><span class="n">idx_upper</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1000</span>

        <span class="k">return</span> <span class="n">out</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        
        <span class="c1"># Computing expected improvement</span>
        <span class="c1"># Negative sign because we want to maximize EI</span>
        <span class="n">out</span><span class="p">[</span><span class="s2">&quot;F&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">penalized_expected_improvement</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> 

<span class="c1"># Optimization algorithm</span>
<span class="n">algorithm</span> <span class="o">=</span> <span class="n">DE</span><span class="p">(</span><span class="n">pop_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">CR</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">dither</span><span class="o">=</span><span class="s2">&quot;vector&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The block of code below creates 20 training points using the same random state as EI and performs the sequential sampling process using dimensionality reduction and EI. The convergence criterion is set at a maximum number of 45 iterations. At every iteration of the sequential sampling, the data is centered using the mean value. After that, PCA is performed at every iteration of the sampling to reduce the dimensionality of the EI maximization problem using the existing sampling plan at that iteration.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">random_state</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">sampler</span> <span class="o">=</span> <span class="n">LHS</span><span class="p">(</span><span class="n">xlimits</span><span class="o">=</span><span class="n">xlimits</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="s1">&#39;ese&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>

<span class="c1"># Training data</span>
<span class="n">num_train</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">xtrain</span> <span class="o">=</span> <span class="n">sampler</span><span class="p">(</span><span class="n">num_train</span><span class="p">)</span>
<span class="n">ytrain</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">xtrain</span><span class="p">)</span>

<span class="c1"># Variables</span>
<span class="n">itr</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">max_itr</span> <span class="o">=</span> <span class="mi">45</span>
<span class="n">tol</span> <span class="o">=</span> <span class="mf">1e-3</span>
<span class="n">max_EI</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">ybest</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">corr</span> <span class="o">=</span> <span class="s1">&#39;squar_exp&#39;</span>
<span class="n">fs</span> <span class="o">=</span> <span class="mi">12</span>

<span class="c1"># Sequential sampling Loop</span>
<span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="k">while</span> <span class="n">itr</span> <span class="o">&lt;</span> <span class="n">max_itr</span><span class="p">:</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Iteration </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">itr</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
    
    <span class="c1"># Pre-processing data before applying PCA</span>
    <span class="n">center</span> <span class="o">=</span> <span class="n">xtrain</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">xtrain_center</span> <span class="o">=</span> <span class="n">xtrain</span> <span class="o">-</span> <span class="n">center</span> 

    <span class="c1"># Applying PCA to the data</span>
    <span class="n">transform</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">xprime</span> <span class="o">=</span> <span class="n">transform</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">xtrain_center</span><span class="p">)</span>

    <span class="c1"># Defining the bounds as the maximum and minimum value of the PC</span>
    <span class="n">lb</span> <span class="o">=</span> <span class="n">xprime</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">ub</span> <span class="o">=</span> <span class="n">xprime</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>

    <span class="c1"># Initializing the kriging model</span>
    <span class="n">sm</span> <span class="o">=</span> <span class="n">KRG</span><span class="p">(</span><span class="n">theta0</span><span class="o">=</span><span class="p">[</span><span class="mf">1e-2</span><span class="p">],</span> <span class="n">corr</span><span class="o">=</span><span class="n">corr</span><span class="p">,</span> <span class="n">theta_bounds</span><span class="o">=</span><span class="p">[</span><span class="mf">1e-6</span><span class="p">,</span> <span class="mf">1e2</span><span class="p">],</span> <span class="n">print_global</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># Setting the training values</span>
    <span class="n">sm</span><span class="o">.</span><span class="n">set_training_values</span><span class="p">(</span><span class="n">xprime</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">)</span>
    
    <span class="c1"># Creating surrogate model</span>
    <span class="n">sm</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

    <span class="c1"># Find the best observed sample</span>
    <span class="n">ybest</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">ytrain</span><span class="p">))</span>

    <span class="c1"># Find the minimum of surrogate model</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">EI_DR</span><span class="p">(</span><span class="n">sm</span><span class="p">,</span> <span class="n">ybest</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">lb</span><span class="o">=</span><span class="n">lb</span><span class="p">,</span> <span class="n">ub</span><span class="o">=</span><span class="n">ub</span><span class="p">,</span> <span class="n">n_var</span> <span class="o">=</span> <span class="n">xprime</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">pca</span> <span class="o">=</span> <span class="n">transform</span><span class="p">,</span> <span class="n">center</span> <span class="o">=</span> <span class="n">center</span><span class="p">),</span> 
                      <span class="n">algorithm</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    
    <span class="c1"># Inverse transform to the real space</span>
    <span class="n">inverse_X</span> <span class="o">=</span> <span class="n">transform</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">+</span> <span class="n">center</span>
    
    <span class="c1"># Computing true function value at infill point</span>
    <span class="n">y_infill</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">inverse_X</span><span class="p">)</span>

    <span class="c1"># Storing variables</span>
    <span class="k">if</span> <span class="n">itr</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">max_EI</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">result</span><span class="o">.</span><span class="n">F</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">xbest</span> <span class="o">=</span> <span class="n">xtrain</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">ytrain</span><span class="p">)]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">max_EI</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="o">-</span><span class="n">result</span><span class="o">.</span><span class="n">F</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">xbest</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">xbest</span><span class="p">,</span> <span class="n">xtrain</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">ytrain</span><span class="p">)]))</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Maximum EI: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">max_EI</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best observed value: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ybest</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
    
    <span class="c1"># Appending the the new point to the current data set</span>
    <span class="n">xtrain</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span> <span class="n">xtrain</span><span class="p">,</span> <span class="n">inverse_X</span> <span class="p">))</span>
    <span class="n">ytrain</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="n">ytrain</span><span class="p">,</span> <span class="n">y_infill</span> <span class="p">)</span>
    
    <span class="n">itr</span> <span class="o">=</span> <span class="n">itr</span> <span class="o">+</span> <span class="mi">1</span> <span class="c1"># Increasing the iteration number</span>

<span class="n">t2</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="c1"># Printing the final results</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Best obtained point:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;x*: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">xbest</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;f*: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ybest</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>

<span class="c1"># Storing results</span>
<span class="n">pca_xbest</span> <span class="o">=</span> <span class="n">xbest</span>
<span class="n">pca_ybest</span> <span class="o">=</span> <span class="n">ybest</span>
<span class="n">pca_time</span> <span class="o">=</span> <span class="n">t2</span> <span class="o">-</span> <span class="n">t1</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Iteration 1
Maximum EI: 8.101206122176006
Best observed value: -150.53602901269912

Iteration 2
Maximum EI: 24.35809591219134
Best observed value: -205.46718541728967

Iteration 3
Maximum EI: 9.274252846344787
Best observed value: -205.46718541728967

Iteration 4
Maximum EI: 13.081990715579746
Best observed value: -205.46718541728967

Iteration 5
Maximum EI: 12.99963681917075
Best observed value: -205.46718541728967

Iteration 6
Maximum EI: 16.895842823596272
Best observed value: -205.46718541728967

Iteration 7
Maximum EI: 7.9357712652656325
Best observed value: -205.46718541728967

Iteration 8
Maximum EI: 4.99776176110562
Best observed value: -225.37927694788365

Iteration 9
Maximum EI: 5.00937171312586
Best observed value: -225.37927694788365

Iteration 10
Maximum EI: 3.573573071987613
Best observed value: -243.41727796602

Iteration 11
Maximum EI: 2.234177460314492
Best observed value: -245.7420784175569

Iteration 12
Maximum EI: 0.12434559894876973
Best observed value: -245.7420784175569

Iteration 13
Maximum EI: 27.17989512087082
Best observed value: -245.7420784175569

Iteration 14
Maximum EI: 14.08936127746008
Best observed value: -245.7420784175569

Iteration 15
Maximum EI: 4.552937454559284
Best observed value: -245.7420784175569

Iteration 16
Maximum EI: 5.0849444909157135
Best observed value: -245.7420784175569

Iteration 17
Maximum EI: 3.309025588655839
Best observed value: -245.7420784175569

Iteration 18
Maximum EI: 0.9354759041253691
Best observed value: -247.9265027016814

Iteration 19
Maximum EI: 0.2393403896653158
Best observed value: -247.9265027016814

Iteration 20
Maximum EI: 2.853202401337315
Best observed value: -254.841398235717

Iteration 21
Maximum EI: 11.481467859901358
Best observed value: -254.841398235717

Iteration 22
Maximum EI: 2.558823925168365
Best observed value: -254.841398235717

Iteration 23
Maximum EI: 0.026359934505476745
Best observed value: -257.8409601836845

Iteration 24
Maximum EI: 0.41275928343689605
Best observed value: -257.8409601836845

Iteration 25
Maximum EI: 0.21985108615033
Best observed value: -257.8409601836845

Iteration 26
Maximum EI: 4.458964104408812
Best observed value: -257.8409601836845

Iteration 27
Maximum EI: 0.3081879682758799
Best observed value: -262.1085336224983

Iteration 28
Maximum EI: 4.224008282030557
Best observed value: -262.1085336224983

Iteration 29
Maximum EI: 0.19209213753520826
Best observed value: -262.1085336224983

Iteration 30
Maximum EI: 0.1760287266207199
Best observed value: -262.1085336224983

Iteration 31
Maximum EI: 8.29983652404847
Best observed value: -262.1085336224983

Iteration 32
Maximum EI: 2.4104678483884907
Best observed value: -265.88951388566846

Iteration 33
Maximum EI: 0.16276928526318946
Best observed value: -266.59429227358214

Iteration 34
Maximum EI: 0.22549808144920158
Best observed value: -266.59429227358214

Iteration 35
Maximum EI: 0.08170629696069798
Best observed value: -266.59429227358214

Iteration 36
Maximum EI: 0.3599060369250118
Best observed value: -266.59429227358214

Iteration 37
Maximum EI: 0.0873100806710364
Best observed value: -266.59429227358214

Iteration 38
Maximum EI: 2.932988638532323
Best observed value: -266.59429227358214

Iteration 39
Maximum EI: 0.1741619436658024
Best observed value: -266.59429227358214

Iteration 40
Maximum EI: 0.16207109431041555
Best observed value: -266.59429227358214

Iteration 41
Maximum EI: 0.05983065926832676
Best observed value: -266.59429227358214

Iteration 42
Maximum EI: 0.08228169101967442
Best observed value: -266.59429227358214

Iteration 43
Maximum EI: 0.13159592646475393
Best observed value: -266.59429227358214

Iteration 44
Maximum EI: 0.15753894225959075
Best observed value: -266.59429227358214

Iteration 45
Maximum EI: 0.8041647494370316
Best observed value: -266.59429227358214

Best obtained point:
x*: [-0.45588116 -0.68261111 -2.95021739 -1.43089789 -2.78725931  2.65876705
 -2.77834678 -3.36882078 -2.93935834  2.87592376]
f*: -266.59429227358214
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plotting and comparing variation of best value of objective function</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">itr</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">ei_ybest</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;blue&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;EI&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">itr</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">ybest</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;PCA-EI&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Iterations&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Best observed $f^*$&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span> <span class="o">=</span> <span class="mi">14</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="n">itr</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/e5661a5bef67a0d830d857c18db85683a3a6a2d56f2c7339e85da557c578ef05.png" src="../_images/e5661a5bef67a0d830d857c18db85683a3a6a2d56f2c7339e85da557c578ef05.png" />
</div>
</div>
<p>The above comparison of the best observed function values shows that sequential sampling using PCA provides a benefit over standard EI. It can reduce the best observed function value to approximately -266 which is a greater reduction than standard EI within the same number of maximum iterations. It can also be seen that in this particular run, PCA-EI also reduces the objective function quicker than standard EI. PCA-EI can produce a great reduction in the best observed function value as soon as 10 iterations while it can take standard EI 15 iterations to produce a comparable reduction in the best observed function value.</p>
</section>
<section id="sequential-sampling-using-kernel-pca-and-ei-kpca-ei">
<h2>Sequential Sampling using Kernel PCA and EI (KPCA-EI)<a class="headerlink" href="#sequential-sampling-using-kernel-pca-and-ei-kpca-ei" title="Link to this heading">#</a></h2>
<p>The blocks of code below will demonstrate the use of Kernel PCA along with EI to optimize the function using sequential sampling. The idea is the same as PCA-EI and the dimensionality of the problem is reduced from 10 to 5 in this case as well. Penalized EI is used to find the new infill point and the parameters of the sampling are identical to those used for EI and PCA-EI. The difference lies in using Kernel PCA as a dimensionality reduction technique. Kernel PCA is a non-linear dimensionality reduction technique often performing better than PCA. However, it is important to correctly choose the hyperparameters of the Kernel PCA algorithm to ensure the best possible performance. Out of these, the most important hyperparameter is the choice of the kernel and other hyperparameters depend on which kernel is chosen for the algorithm. For this demonstration here, the hyperparameters are chosen as the default values with the kernel choice being the cosine kernel. In general, a procedure such as cross-validation can be used to find the best hyperparameters.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">random_state</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">sampler</span> <span class="o">=</span> <span class="n">LHS</span><span class="p">(</span><span class="n">xlimits</span><span class="o">=</span><span class="n">xlimits</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="s1">&#39;ese&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>

<span class="c1"># Training data</span>
<span class="n">num_train</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">xtrain</span> <span class="o">=</span> <span class="n">sampler</span><span class="p">(</span><span class="n">num_train</span><span class="p">)</span>
<span class="n">ytrain</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">xtrain</span><span class="p">)</span>

<span class="c1"># Variables</span>
<span class="n">itr</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">max_itr</span> <span class="o">=</span> <span class="mi">45</span>
<span class="n">tol</span> <span class="o">=</span> <span class="mf">1e-3</span>
<span class="n">max_EI</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">ybest</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">corr</span> <span class="o">=</span> <span class="s1">&#39;squar_exp&#39;</span>
<span class="n">fs</span> <span class="o">=</span> <span class="mi">12</span>

<span class="c1"># Sequential sampling Loop</span>
<span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="k">while</span> <span class="n">itr</span> <span class="o">&lt;</span> <span class="n">max_itr</span><span class="p">:</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Iteration </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">itr</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
    
    <span class="c1"># Pre-processing data before applying KPCA</span>
    <span class="n">center</span> <span class="o">=</span> <span class="n">xtrain</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">xtrain_center</span> <span class="o">=</span> <span class="n">xtrain</span> <span class="o">-</span> <span class="n">center</span> 

    <span class="c1"># Applying KPCA to the data</span>
    <span class="n">transform</span> <span class="o">=</span> <span class="n">KernelPCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;cosine&#39;</span><span class="p">,</span> <span class="n">fit_inverse_transform</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">xprime</span> <span class="o">=</span> <span class="n">transform</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">xtrain_center</span><span class="p">)</span>
    
    <span class="c1"># Defining the bounds as the maximum and minimum value of the PC</span>
    <span class="n">lb</span> <span class="o">=</span> <span class="n">xprime</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">ub</span> <span class="o">=</span> <span class="n">xprime</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>

    <span class="c1"># Initializing the kriging model</span>
    <span class="n">sm</span> <span class="o">=</span> <span class="n">KRG</span><span class="p">(</span><span class="n">theta0</span><span class="o">=</span><span class="p">[</span><span class="mf">1e-2</span><span class="p">],</span> <span class="n">corr</span><span class="o">=</span><span class="n">corr</span><span class="p">,</span> <span class="n">theta_bounds</span><span class="o">=</span><span class="p">[</span><span class="mf">1e-6</span><span class="p">,</span> <span class="mf">1e2</span><span class="p">],</span> <span class="n">print_global</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># Setting the training values</span>
    <span class="n">sm</span><span class="o">.</span><span class="n">set_training_values</span><span class="p">(</span><span class="n">xprime</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">)</span>
    
    <span class="c1"># Creating surrogate model</span>
    <span class="n">sm</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

    <span class="c1"># Find the best observed sample</span>
    <span class="n">ybest</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">ytrain</span><span class="p">))</span>

    <span class="c1"># Find the minimum of surrogate model</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">EI_DR</span><span class="p">(</span><span class="n">sm</span><span class="p">,</span> <span class="n">ybest</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">lb</span><span class="o">=</span><span class="n">lb</span><span class="p">,</span> <span class="n">ub</span><span class="o">=</span><span class="n">ub</span><span class="p">,</span> <span class="n">n_var</span> <span class="o">=</span> <span class="n">xprime</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">pca</span> <span class="o">=</span> <span class="n">transform</span><span class="p">,</span> <span class="n">center</span> <span class="o">=</span> <span class="n">center</span><span class="p">),</span> 
                      <span class="n">algorithm</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    
    <span class="c1"># Inverse transform to the real space</span>
    <span class="n">inverse_X</span> <span class="o">=</span> <span class="n">transform</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">+</span> <span class="n">center</span>
    
    <span class="c1"># Computing true function value at infill point</span>
    <span class="n">y_infill</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">inverse_X</span><span class="p">)</span>

    <span class="c1"># Storing variables</span>
    <span class="k">if</span> <span class="n">itr</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">max_EI</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">result</span><span class="o">.</span><span class="n">F</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">xbest</span> <span class="o">=</span> <span class="n">xtrain</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">ytrain</span><span class="p">)]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">max_EI</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="o">-</span><span class="n">result</span><span class="o">.</span><span class="n">F</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">xbest</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">xbest</span><span class="p">,</span> <span class="n">xtrain</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">ytrain</span><span class="p">)]))</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Maximum EI: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">max_EI</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best observed value: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ybest</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
    
    <span class="c1"># Appending the the new point to the current data set</span>
    <span class="n">xtrain</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span> <span class="n">xtrain</span><span class="p">,</span> <span class="n">inverse_X</span> <span class="p">))</span>
    <span class="n">ytrain</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="n">ytrain</span><span class="p">,</span> <span class="n">y_infill</span> <span class="p">)</span>
    
    <span class="n">itr</span> <span class="o">=</span> <span class="n">itr</span> <span class="o">+</span> <span class="mi">1</span> <span class="c1"># Increasing the iteration number</span>

<span class="n">t2</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="c1"># Printing the final results</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Best obtained point:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;x*: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">xbest</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;f*: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ybest</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>

<span class="c1"># Storing time cost results</span>
<span class="n">kpca_time</span> <span class="o">=</span> <span class="n">t2</span> <span class="o">-</span> <span class="n">t1</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Iteration 1
Maximum EI: 6.979328418587719
Best observed value: -150.53602901269912

Iteration 2
Maximum EI: 14.658139415927149
Best observed value: -170.46470349227047

Iteration 3
Maximum EI: 20.1589800042305
Best observed value: -170.46470349227047

Iteration 4
Maximum EI: 23.678652636989206
Best observed value: -170.46470349227047

Iteration 5
Maximum EI: 22.333801998614614
Best observed value: -184.02537973814339

Iteration 6
Maximum EI: 11.787397259763061
Best observed value: -184.02537973814339

Iteration 7
Maximum EI: 8.564722651169953
Best observed value: -200.4633181316592

Iteration 8
Maximum EI: 19.383629111558356
Best observed value: -200.4633181316592

Iteration 9
Maximum EI: 11.598636620415027
Best observed value: -200.4633181316592

Iteration 10
Maximum EI: 27.777033778937273
Best observed value: -200.741739458622

Iteration 11
Maximum EI: 17.476895468219578
Best observed value: -222.47232321053272

Iteration 12
Maximum EI: 2.828804966837966
Best observed value: -226.77821442939643

Iteration 13
Maximum EI: 2.093080022861404
Best observed value: -226.77821442939643

Iteration 14
Maximum EI: 36.78900180295359
Best observed value: -226.77821442939643

Iteration 15
Maximum EI: 6.91967866795145
Best observed value: -226.77821442939643

Iteration 16
Maximum EI: 1.0092358332399387
Best observed value: -230.19251751686755

Iteration 17
Maximum EI: 2.6917148769576684
Best observed value: -230.19251751686755

Iteration 18
Maximum EI: 15.323822959118502
Best observed value: -230.19251751686755

Iteration 19
Maximum EI: 16.59364783171235
Best observed value: -240.58337700761038

Iteration 20
Maximum EI: 25.776170368710865
Best observed value: -240.58337700761038

Iteration 21
Maximum EI: 0.5038908704460581
Best observed value: -260.05338441523054

Iteration 22
Maximum EI: 14.407819059981964
Best observed value: -260.05338441523054

Iteration 23
Maximum EI: 1.4454184563108052
Best observed value: -260.05338441523054

Iteration 24
Maximum EI: 6.019382910020652
Best observed value: -260.05338441523054

Iteration 25
Maximum EI: 4.5972566332106295
Best observed value: -260.05338441523054

Iteration 26
Maximum EI: 2.315909194900626
Best observed value: -260.05338441523054

Iteration 27
Maximum EI: 5.5852358250357295
Best observed value: -263.7205076741951

Iteration 28
Maximum EI: 5.461178262849945
Best observed value: -263.7744758020681

Iteration 29
Maximum EI: 16.38643809749153
Best observed value: -266.67015427150267

Iteration 30
Maximum EI: 15.952743496498693
Best observed value: -266.67015427150267

Iteration 31
Maximum EI: 2.0069282672436923
Best observed value: -270.0275420695992

Iteration 32
Maximum EI: 11.691963566216362
Best observed value: -270.0275420695992

Iteration 33
Maximum EI: 6.99591121379315
Best observed value: -274.6414600958959

Iteration 34
Maximum EI: 14.109187185199835
Best observed value: -275.63431485544015

Iteration 35
Maximum EI: 1.186713898355313
Best observed value: -275.63431485544015

Iteration 36
Maximum EI: 14.103625472127717
Best observed value: -275.63431485544015

Iteration 37
Maximum EI: 14.559959436662169
Best observed value: -275.63431485544015

Iteration 38
Maximum EI: 23.466578742679058
Best observed value: -275.63431485544015

Iteration 39
Maximum EI: 22.55633445942511
Best observed value: -275.63431485544015

Iteration 40
Maximum EI: 14.101084536083814
Best observed value: -275.63431485544015

Iteration 41
Maximum EI: 7.663264346174696
Best observed value: -275.63431485544015

Iteration 42
Maximum EI: 24.756814203760957
Best observed value: -275.63431485544015

Iteration 43
Maximum EI: 1.889612469572274
Best observed value: -275.63431485544015

Iteration 44
Maximum EI: 13.254451260931232
Best observed value: -275.63431485544015

Iteration 45
Maximum EI: 7.000151105031634
Best observed value: -275.63431485544015

Best obtained point:
x*: [ 1.74424182 -2.64825621 -2.80702381 -3.15897731 -1.44621292 -0.01283508
  2.86725298 -3.00205901 -3.03599154  2.52315888]
f*: -275.63431485544015
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plotting and comparing variation of best value of objective function</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">itr</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">ei_ybest</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;blue&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;EI&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">itr</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">pca_ybest</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;PCA-EI&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">itr</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">ybest</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;green&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;KPCA-EI&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Iterations&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Best observed $f^*$&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span> <span class="o">=</span> <span class="mi">14</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="n">itr</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/3b8d697355994824d595a82c7c0700090f586c731f191b69b989bd4518ccda0c.png" src="../_images/3b8d697355994824d595a82c7c0700090f586c731f191b69b989bd4518ccda0c.png" />
</div>
</div>
<p>The above plot shows that KPCA-EI can produce a reduction in the best observed value of the function which is greater than both standard EI and PCA-EI. KPCA-EI is able to reduce the best observed value to approximately -275. It is, therefore, the best performing method in this run according to the best observed value of the objective function. However, in this run, it is not as quick as PCA-EI and standard EI to reduce the objective function value. In fact, it can take almost 21 iterations for KPCA-EI to produce a reduction in the objective that is comparable to standard EI and PCA-EI. It is also important to remember that the performance of KPCA-EI depends on the choice of hyperparameters for KPCA which significantly affect the dimensionality reduction and performance of the algorithm.</p>
<p>The final block of code below shows the total time cost of each of the sequential sampling algorithms shown in this section. The results show that the use of dimensionality reduction techniques reduces the overall time cost of sequentially sampling a high-dimensional function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">methods</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;EI&#39;</span><span class="p">,</span> <span class="s1">&#39;PCA-EI&#39;</span><span class="p">,</span> <span class="s1">&#39;KPCA-EI&#39;</span><span class="p">]</span>
<span class="n">times</span> <span class="o">=</span> <span class="p">[</span><span class="n">ei_time</span><span class="p">,</span> <span class="n">pca_time</span><span class="p">,</span> <span class="n">kpca_time</span><span class="p">]</span>
<span class="n">ax</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">methods</span><span class="p">,</span> <span class="n">times</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Methods&quot;</span><span class="p">,</span> <span class="n">fontsize</span> <span class="o">=</span> <span class="mi">14</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Time Cost (s)&quot;</span><span class="p">,</span> <span class="n">fontsize</span> <span class="o">=</span> <span class="mi">14</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/995c2a39b624092661a3df330fa2aab9422f200ac6e22328e08662f77b545a67.png" src="../_images/995c2a39b624092661a3df330fa2aab9422f200ac6e22328e08662f77b545a67.png" />
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./dim_reduction"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sequential-sampling-using-expected-improvement-ei">Sequential Sampling using Expected Improvement (EI)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sequential-sampling-using-pricinpal-component-analysis-and-ei-pca-ei">Sequential Sampling using Pricinpal Component Analysis and EI (PCA-EI)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sequential-sampling-using-kernel-pca-and-ei-kpca-ei">Sequential Sampling using Kernel PCA and EI (KPCA-EI)</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By CODE Lab
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
       Copyright 2026.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>