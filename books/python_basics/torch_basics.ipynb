{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36c9594d",
   "metadata": {},
   "source": [
    "# Basics of PyTorch tensor computations\n",
    "\n",
    "This is a tutorial on basic tensor computations that can be performed using the PyTorch framework. This will be the main framework used to construct surrogate models within this Jupyter Book. It is important to know the basics of PyTorch tensor computations to understand the surrogate modeling methods. \n",
    "\n",
    "A PyTorch tensor is the analogue of a numpy array for the PyTorch framework, which is a very popular library for machine learning and creating surrogate models. Tensors are multi-dimensional arrays that are the basic unit of computation for the PyTorch framework. These will be used extensively for creating models and other computations. Tensors provide the user with the capability of performing computations on a Graphical Processing Unit (GPU) which can significantly accelerate computations. Here, we will cover some basic computations using PyTorch tensors. Further details are given within comments in the code blocks.\n",
    "\n",
    "The first step is to import the PyTorch library which is imported through the name `torch`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "31d0d0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing torch for tensor computations\n",
    "import torch\n",
    "\n",
    "# Also importing numpy as it is needed to show numpy to torch conversions and vice versa\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "31997f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D tensor: tensor([1., 2., 3.])\n",
      "2D tensor: tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "3D tensor: tensor([[[1., 2.],\n",
      "         [3., 4.]],\n",
      "\n",
      "        [[5., 6.],\n",
      "         [7., 8.]]])\n"
     ]
    }
   ],
   "source": [
    "# Creating a new 1D tensor array\n",
    "a_tensor = torch.tensor([1.0, 2.0, 3.0])\n",
    "print(\"1D tensor:\", a_tensor)\n",
    "\n",
    "# Creating a new 2D tensor array\n",
    "b_tensor = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "print(\"2D tensor:\", b_tensor)\n",
    "\n",
    "# It is also possible to create a 3D tensor\n",
    "c_tensor = torch.tensor([[[1.0, 2.0], [3.0, 4.0]], [[5.0,6.0], [7.0,8.0]]])\n",
    "print(\"3D tensor:\", c_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e516b43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of a_tensor: 1\n",
      "Dimension of b_tensor: 2\n",
      "Dimension of c_tensor: 3\n"
     ]
    }
   ],
   "source": [
    "# Acessing the dimension of the tensor\n",
    "# Here, we are printing the values using a f string which is useful for printing strings and variables\n",
    "print(f\"Dimension of a_tensor: {a_tensor.ndim}\")\n",
    "print(f\"Dimension of b_tensor: {b_tensor.ndim}\")\n",
    "print(f\"Dimension of c_tensor: {c_tensor.ndim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ff2eda29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of a_tensor: torch.Size([3])\n",
      "Shape of b_tensor: torch.Size([2, 2])\n",
      "Shape of c_tensor: torch.Size([2, 2, 2])\n",
      "First index of b_tensor shape: 2\n",
      "Second index of b_tensor shape: 2\n"
     ]
    }
   ],
   "source": [
    "# Accessing the shape of the tensor. Think of this as matrix dimensions if 2D or vector length if 1D\n",
    "print(f\"Shape of a_tensor: {a_tensor.shape}\")\n",
    "print(f\"Shape of b_tensor: {b_tensor.shape}\")\n",
    "print(f\"Shape of c_tensor: {c_tensor.shape}\")\n",
    "# The above returns a torch.Size array which can be indexed like a regular array\n",
    "# Indexing shape of b_tensor\n",
    "print(f\"First index of b_tensor shape: {b_tensor.shape[0]}\")\n",
    "print(f\"Second index of b_tensor shape: {b_tensor.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3b6a1b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of a_tensor: torch.Size([3])\n",
      "Size of b_tensor: torch.Size([2, 2])\n",
      "Size of c_tensor: torch.Size([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# The size method associated with a tensor can also be called to obtain the shape of the tensor array\n",
    "print(f\"Size of a_tensor: {a_tensor.size()}\")\n",
    "print(f\"Size of b_tensor: {b_tensor.size()}\")\n",
    "print(f\"Size of c_tensor: {c_tensor.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4251d6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D array of zeros: tensor([0., 0., 0., 0., 0.])\n",
      "2D array of ones: tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Some standard tensors such as a tensor with all zeros or all ones can also be defined as follows\n",
    "# The numbers in the parentheses define the shape of the array, similar to the Numpy library\n",
    "zero_tensor = torch.zeros(5) # 1D array of zeros\n",
    "print(f\"1D array of zeros: {zero_tensor}\")\n",
    "\n",
    "ones_tensor = torch.ones((5,2)) # 2D array of ones\n",
    "print(f\"2D array of ones: {ones_tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ba3ec141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evenly spaced tensor: tensor([0.0000, 0.0526, 0.1053, 0.1579, 0.2105, 0.2632, 0.3158, 0.3684, 0.4211,\n",
      "        0.4737, 0.5263, 0.5789, 0.6316, 0.6842, 0.7368, 0.7895, 0.8421, 0.8947,\n",
      "        0.9474, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "# It is also possible to create an evenly spaced tensor array using torch.linspace similar to MATLAB and Numpy\n",
    "linear_tensor = torch.linspace(0,1,20)\n",
    "print(f\"Evenly spaced tensor: {linear_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7f9869",
   "metadata": {},
   "source": [
    "We can index tensor arrays in a manner that is similar to indexing Numpy arrays. The next code block demonstrates examples of indexing different types of tensor arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "48a178bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First element of a_tensor: 1.0\n",
      "Second element of a_tensor: 2.0\n"
     ]
    }
   ],
   "source": [
    "# Indexing a 1D tensor array\n",
    "print(f\"First element of a_tensor: {a_tensor[0]}\")\n",
    "print(f\"Second element of a_tensor: {a_tensor[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3953f4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element of b_tensor in first row and first column: 1.0\n",
      "Element of b_tensor in second row and first column: 3.0\n",
      "Value of element of b_tensor in first row and first column: 1.0\n",
      "Value of element of b_tensor in second row and first column: 3.0\n"
     ]
    }
   ],
   "source": [
    "# Indexing a 2D array\n",
    "print(f\"Element of b_tensor in first row and first column: {b_tensor[0,0]}\")\n",
    "print(f\"Element of b_tensor in second row and first column: {b_tensor[1][0]}\")\n",
    "# It is important to note that the above will return a 0-dim tensor which is essentially the representation of a single value within PyTorch\n",
    "# To recover the single value from the tensor it is necessary to use the item method\n",
    "print(f\"Value of element of b_tensor in first row and first column: {b_tensor[0,0].item()}\")\n",
    "print(f\"Value of element of b_tensor in second row and first column: {b_tensor[1][0].item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a4f2fb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element of c_tensor in first row, first column and first position along depth: 1.0\n",
      "Element of c_tensor in second row, first column and second along the depth: 6.0\n"
     ]
    }
   ],
   "source": [
    "# Indexing a 3D array and extracting the value using the item method\n",
    "# The term depth in this case is used to indicate the third dimension of the array\n",
    "print(f\"Element of c_tensor in first row, first column and first position along depth: {c_tensor[0,0,0].item()}\")\n",
    "print(f\"Element of c_tensor in second row, first column and second along the depth: {c_tensor[1][0][1].item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750ac9fd",
   "metadata": {},
   "source": [
    "Just like the Numpy library, it is also important to know how to reshape tensor arrays in case it is needed for building models or using tensors with other libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cc339fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of a_tensor: torch.Size([3])\n",
      "New shape of a_tensor: torch.Size([1, 3])\n",
      "New shape of a_tensor: torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "# Reshaping aTensor from shape torch.Size([3]) to torch.Size([1,3])\n",
    "print(f\"Shape of a_tensor: {a_tensor.shape}\")\n",
    "a_tensor_reshaped_1 = a_tensor.reshape(1,3)\n",
    "print(f\"New shape of a_tensor: {a_tensor_reshaped_1.shape}\")\n",
    "\n",
    "# This can also be done by using -1 for one of the dimensions in the shape definition.\n",
    "# If -1 is used then the dimension will match the remaining number of total elements in the array. \n",
    "a_tensor_reshaped_2 = a_tensor.reshape(1,-1)\n",
    "print(f\"New shape of a_tensor: {a_tensor_reshaped_2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b550b6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of b_tensor: torch.Size([2, 2])\n",
      "New shape of b_tensor: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "# Reshaping b_tensor from shape torch.Size([2,2]) to torch.Size([1,4])\n",
    "print(f\"Shape of b_tensor: {b_tensor.shape}\")\n",
    "b_tensor_reshaped = b_tensor.reshape(1,4)\n",
    "print(f\"New shape of b_tensor: {b_tensor_reshaped.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5083b0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of c_tensor: torch.Size([2, 2, 2])\n",
      "New shape of c_tensor: torch.Size([2, 4])\n",
      "New shape of c_tensor: torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "# Reshaping c_tensor from shape torch.Size([2,2,2]) to torch.Size([2,4])\n",
    "# This can be done using -1 or using 4 as the dimension size\n",
    "print(f\"Shape of c_tensor: {c_tensor.shape}\")\n",
    "c_tensor_reshaped_1 = c_tensor.reshape(2,4)\n",
    "print(f\"New shape of c_tensor: {c_tensor_reshaped_1.shape}\")\n",
    "\n",
    "c_tensor_reshaped_2 = c_tensor.reshape(2,-1)\n",
    "print(f\"New shape of c_tensor: {c_tensor_reshaped_2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0b18e0f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[2, 6]' is invalid for input of size 8",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[77]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m c_tensor_reshaped_3 = \u001b[43mc_tensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# This will give an error as there not enough elements in c_tensor to support this reshape\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# c_tensor has 6 elements but the above reshape requires 8 elements\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: shape '[2, 6]' is invalid for input of size 8"
     ]
    }
   ],
   "source": [
    "c_tensor_reshaped_3 = c_tensor.reshape(2,6) # This will give an error as there not enough elements in c_tensor to support this reshape\n",
    "# c_tensor has 6 elements but the above reshape requires 8 elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19534612",
   "metadata": {},
   "source": [
    "On occasion, it is necessary to convert between Numpy arrays and PyTorch tensors to use data stored within arrays with particular libraries or for the purposes of plotting. The following blocks of code provide examples of coverting between Numpy arrays and PyTorch tensors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "89150920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy array: [[1. 2. 3.]\n",
      " [4. 6. 8.]]\n",
      "Tensor conversion 1: tensor([[1., 2., 3.],\n",
      "        [4., 6., 8.]], dtype=torch.float64)\n",
      "Tensor conversion 2: tensor([[1., 2., 3.],\n",
      "        [4., 6., 8.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Converting a numpy array to a torch tensor array\n",
    "array_numpy = np.array([[1.0,2.0,3.0],[4.0,6.0,8.0]])\n",
    "print(f\"Numpy array: {array_numpy}\")\n",
    "\n",
    "# Two examples of methods to convert numpy array to tensor\n",
    "array_tensor_1 = torch.from_numpy(array_numpy)\n",
    "print(f\"Tensor conversion 1: {array_tensor_1}\")\n",
    "\n",
    "array_tensor_2 = torch.tensor(array_numpy)\n",
    "print(f\"Tensor conversion 2: {array_tensor_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "866f09f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor array: tensor([[1., 2., 3.],\n",
      "        [4., 6., 8.]])\n",
      "Numpy array: [[1. 2. 3.]\n",
      " [4. 6. 8.]]\n"
     ]
    }
   ],
   "source": [
    "# Converting torch tensor array to numpy array\n",
    "array_tensor = torch.tensor([[1.0,2.0,3.0],[4.0,6.0,8.0]])\n",
    "print(f\"Tensor array: {array_tensor}\")\n",
    "\n",
    "array_numpy = array_tensor.numpy()\n",
    "print(f\"Numpy array: {array_numpy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c363bad",
   "metadata": {},
   "source": [
    "Tensor computations can be performed both on a CPU as well as a GPU. However, using a GPU can be beneficial due to the acceleration that GPU tensor computations can provide. To indicate whether a GPU or CPU should be used for the computations, it is necessary to specify the `device` for a tensor array. It is also sometimes necessary to transfer a tensor hosted on the GPU to the CPU or vice versa for other computations or plotting purposes. This transfer is also necessary before converting the tensor array to a numpy array.\n",
    "\n",
    "Additionally, you may have noticed the `dtype` being printed for a tensor. The `dtype` indicates the floating point precision for the tensor array. `torch.float32` indicates 32-bit or single precision and `torch.float64` indicates 64-bit or double precision. The following code blocks provide examples on specifying the `device` and `dtype` for a tensor array. They also show examples of transferring tensors between GPUs and CPUs on a machine. \n",
    "\n",
    "The first code block demonstrates how to check if a GPU is available for tensor computations. If a dedicated GPU with CUDA is not available on your machine, then this will show False. Otherwise, it should show true. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "19da0bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Checking to see if GPU is available\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2f1c7746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_tensor dtype: torch.float32\n",
      "d_tensor device: cpu\n",
      "e_tensor dtype: torch.float64\n",
      "e_tensor device: cuda:0\n",
      "f_tensor dtype: torch.float32\n",
      "f_tensor device: cuda:0\n",
      "g_tensor dtype: torch.float64\n",
      "g_tensor device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Defining a tensor with explicitly mentioned device and dtype\n",
    "d_tensor = torch.tensor([[1.0,2.0], [3.0,4.0]], dtype=torch.float32, device=\"cpu\") # \"cpu\" indicates that the CPU is being used for computations\n",
    "print(f\"d_tensor dtype: {d_tensor.dtype}\")\n",
    "print(f\"d_tensor device: {d_tensor.device}\")\n",
    "\n",
    "e_tensor = torch.tensor([[1.0,2.0], [3.0,4.0]], dtype=torch.float64, device=\"cuda\") # \"cuda\" indicates that the GPU is being used for computations\n",
    "print(f\"e_tensor dtype: {e_tensor.dtype}\")\n",
    "print(f\"e_tensor device: {e_tensor.device}\")\n",
    "\n",
    "# Another method for changing dtype and device\n",
    "f_tensor = torch.tensor([[1.0,2.0], [3.0,4.0]], dtype=torch.float64)\n",
    "f_tensor = f_tensor.to(dtype=torch.float32, device=\"cuda\")\n",
    "print(f\"f_tensor dtype: {f_tensor.dtype}\")\n",
    "print(f\"f_tensor device: {f_tensor.device}\")\n",
    "\n",
    "# It is also possible to use the to() method to set the dtype and device of one tensor the same as another tensor\n",
    "g_tensor = torch.tensor([[1.0,2.0], [3.0,4.0]], dtype=torch.float32, device=\"cpu\")\n",
    "g_tensor = f_tensor.to(e_tensor)\n",
    "print(f\"g_tensor dtype: {g_tensor.dtype}\")\n",
    "print(f\"g_tensor device: {g_tensor.device}\")\n",
    "\n",
    "# g_tensor has same dtype and device as e_tensor even though the original definition is different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bf17f98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Transferring a GPU tensor to the CPU\n",
    "e_tensor_cpu = e_tensor.cpu()\n",
    "print(f\"Tensor device: {e_tensor_cpu.device}\") # Device has been converted to cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b59bc2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e_tensor data type: <class 'torch.Tensor'>\n",
      "e_tensor_numpy data type: <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[83]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33me_tensor_numpy data type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(e_tensor_numpy)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;66;03m# tensor has been converted to numpy\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# The below code line will give an error since the tensor has not been transferred to the cpu first\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m e_tensor_numpy = \u001b[43me_tensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "# Converting to numpy can only be done after the tensor is transferred to the CPU\n",
    "e_tensor_numpy = e_tensor.cpu().numpy()\n",
    "print(f\"e_tensor data type: {type(e_tensor)}\") # tensor has been converted to numpy\n",
    "print(f\"e_tensor_numpy data type: {type(e_tensor_numpy)}\") # tensor has been converted to numpy\n",
    "\n",
    "# The below code line will give an error since the tensor has not been transferred to the cpu first\n",
    "e_tensor_numpy = e_tensor.numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "surrogate_methods_sp26",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
